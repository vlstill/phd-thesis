\TODO{Level of verification - TODO (C++ x LLVM x ASM)}

\srcnote{Text of this chapter is in part extension of~\mcite{SRB2017}.
The text was brought up to date with certain implementation details of DIVINE
and extended with the wider context of analysis of realistic programs in
DIVINE.
The benchmarks are unmodified from the original paper.}

\bigskip\noindent
An important step toward adoption of formal methods in software development is
support for mainstream programming languages.
These languages are often rather complex and come with substantial standard
libraries.
However, by choosing a suitable intermediate language, most of the complexity
can be delegated to existing execution-oriented (as opposed to
verification-oriented) compiler frontends and standard library implementations.
In this chapter, we describe how support for the C and C++ including their
standard librararies and for C++ exceptions in DIVINE can be done by using
these principles.

% Our implementation consists of 2 parts: an implementation of the
% \texttt{libunwind} platform API which is linked to the program under
% test and consists of 9 C functions. The other part is a preprocessor for
% \llvm{} bitcode which prepares exception-related metadata and replaces
% associated special-purpose \llvm{} instructions.

As we have already outlined in \autoref{sec:prelim:programs}, realistic
programs have many features not present in verification-centric modelling
languages.
For example C has dynamic memory and pointer arithmetic (i.e., it is possible
to access elements of arrays and data structures by numberic manipulation of
pointer values) and function pointers.
Languages with support for object-oriented programming like C++, C\#, and Java
have inheritance and dynamic dispatch of member functions based on the runtime
type of the object they are caled on.
Many languages also have exceptions which allow for non-local transfer of
control between functions.
C++ is particualrly complex, featuring things like function and class
templates,
\mnote{Templates allow the programmer to write a generic code which
    does not depend on the concrete type, the compiler is then responsible for
    generation of implementations for concrete types the code is used with.}
inheritance with multiple base classes, runtime type information (RTTI),
compiler-generated special member functions,
\mnote{C++ compiler can auto-generate code which handles copying, creation and
    destruction of objects, and since C++20 also comparison of objects. Of
    course the programmer can override the default behaviour in case it is not
    sufficient, for example when implementing resource abstractions.}
and support for concurrency including low-level atomic access.
To make work for developers of analysis tools (and compiler and standard
libraries) harder, many of these languages are also under constant development,
for example C++ releases a new standardy every three years since 2011, with
major new language and library features added in each new revision.
C++ compilers and standard libraries which keep up-to-date with the standard
are usually developed either by big companies like Microsoft or Intel, or by
large community efforts like GCC and clang (whith clang being also supported by
Apple).

Considering the efforst put into compiler development and the complexity of
programming languages like C++, it makes sence to reuse as much of the existing
execution-oriented infrastructure which exists around thse programming
languages.
Re-implementing this infrastructure could easily consume large portion of the
limited resources of developers of verification tools.
For example, DIVINE and many other tool for analysis of C and C++, use the
clang compiler to translate C and C++ into LLVM intermediate representation
(IR).
Similar approach can be applied to any language which uses LLVM in its
translation (e.g., Rust, Swift, Objective-C), to Java (by tranalating it to
Java Virtual Machine bytecode), or to C\# (by translating it to Common Language
Infrastructure).
For libraries existing open-source versions can also be used for verification to some extend.

The rest of this chapter is structured as follows: \autoref{sec:lang:adv} takes a deeper look at advantages and disadvantages of reusal of execution-oriented components for program verification.
\autoref{sec:lang:divine} then describes how DIVINE uses existing components in analysis of C and C++ and why the C standard library cannot be fully re-used from execution-oriented implementations.
\autoref{sec:lang:except} then takes more detailed look at the particular case of excetion support in DIVINE 4, which was originally published in~\mcite{SRB2017}.

% The paper is structured as follows: the remainder of
% \autoref{sec:introduction} gives motivation, context and
% contribution of this work. \autoref{sec:exceptions} describes the
% mechanisms that C++ implementations typically use in order to support
% exceptions. The following \autoref{sec:execution} then details how
% \llvm{} is interpreted in \divine{} 4, in particular the parts relevant to
% exception handling, such as the stack layout.
% \autoref{sec:transform} and \autoref{sec:unwinder} discuss the
% new components: the \llvm{} transformation and the unwinder, respectively.
% \autoref{sec:related} surveys the related work and finally, in
% \autoref{sec:evaluation}, we evaluate our approach and we summarise
% our findings in \autoref{sec:conclusion}.

\section{Component Reuse in Program Analysis}\label{sec:lang:adv}

Reusal of execution-oriented componenents (such as compilers and libraries) for
program analysis is a compromise and it is important to know the advantages and
disadvantages of component reuse.
On one hand, reuse can save developement time and offload the significant cost
of development and testing to a third parties and therefore enable support for the whole complexity of the given programming language.
This is important as the whole reason for analysis of realistic programming languages is to enable the programmer to use the the tool for analysis of the code they normally write, not a code written in a small subset of their language of choice.
Furthermore, reusal can also increase precision of program analysis for the cases where the same components are used for analysis and execution -- for example if the same optimizing compiler is used in both situations and an optimized intermediate representation is used for the analysis, the analysis tool can now also find problems introduced by the compiler's optimizer (which is quite complex and error-prone) which were not in the original code.
On the other hand, potential problems whith the reused components can also
impact verification precisiton negatively, especially if they are able to hide
problems is the analysed code.
Even if there were no bugs in the reused components and they adhered to specification, the problem is that these components can under-approximate all behaviours allowed by the standard.
The execution-oriented components are also usually performance oriented, which might make the task of program analysis harder.

\subsection{Compilation}

Compilers are now routinely re-used in verifiers, with the LLVM toolchain and
clang compiler being especially populer in the are of C (and C++) analysis.
Many program analysis tools are in fact analysing the LLVM IR and not C
directly (for example DIVINE~\mcite{DIVINEToolPaper2017},
Skink~\mcite{Cassez2017}, VVT~\mcite{Gunther2016}, Symbiotic~\mcite{Chalupa2018},
and many more).
Building a verfier for LLVM IR is simpler since LLVM IR abstracts from many of
the high-level concepts and presents only a reasonable amount of instructions
which has to be implemented.
The clang compiler (which can compile C and C++ to LLVM IR) can handle many
features of the progamming languages in such a way that the program analysis
tools does not need to know about them.
For example template instantiation, function overloading, dynamic dispatch, and
local variable lifetime (in absence of exceptions) are handled in this way.
The complete problem of parsing the rich grammar of the language such as C++ is
also handled by the compiler and various control-flow constructs are translated
to simple jumps.

One of the disadvantages of this approach is that the analysis tool loses some
information present in the original code.
For example, a loop condition is often more clearly represented in the original
code than in the LLVM IR where it has to be extracted from the value used in
the conditional branch.
Another disadvantage is the loss of possible behaviours -- for example the C++ standards leaves the order of evaluation of function argument uspecified, letting the compiler to optimize the code by evaluating them in any order necessary.
However, on the level of LLVM IR, the evaluation order is already fixed.

Some of these disadvantages can be mitigated by reusing less of the compilation
infastructure, for example using an approach similar to the one taked by
ESBMC~\mcite{Gadelha2018}, which uses only the C and C++ parser from clang,
building their own intermediate represenation from the abstract systax tree.
\TODO{However, it does not appear that ESBMC takes advantage of the additional information to check for bugs caused by reliance on unspecified behaviour defined in the C/C++ standards.}
Nevertheless, there is a cost to pay for the increased precision -- for example, ESBMC has to be able to handle many of the language features which are abstracted away in the compilation.

\subsection{Libaries}

Programmers expect not only the language features, but also the standard
libraries to work in the program analyser.
The standard libraries provide the basic features such as the data structures, algorithms, access to the filesystem, and in C and C++ also for exmaple threading support and memory allocation.

Clearly, any program analysis tool for C which has support for dynamic memory
will need to support at least the parts of library which allow its management
(\cpp{malloc}, \cpp{free}, …) and any tool which supports threading will need
the support for thread spawning.
These parts of the library will be specific to the analysis tool -- which in
this context plays the same role as the operating system in the program
exection.
Nevertheless, large parts of the C standard library, and almost all of the C++
standard library is independent of the operating system it executes on and by
extension is also independent on whether it is used in the context of execution
or program analysis.

The advantages and disadvantages of library reusal are in part similar to the
once mentioned for compilers -- the library is already tested and developed by
an external entidy, but it can contain bugs, or it may use design choices which
are correct implementation of the standard, but limit possible behaviours of
the program to a subset of behaviours allowed by te standard.
However, there are some specifics to library reusal.
Many of the bugs potentially present in a library can be actually caught if the
library is treated by the analysis tool as a part of the analysed program -- in
this way reusal of libraries can lead to discovery of bugs in the library and
therefore help to ensure correctness of the code which uses the
library.\mnote{An example is the data race in initialization of C++ threads in
\texttt{libc++} discovered by DIVINE which was later fixed by the
\texttt{libc++} developers.}
The same feature also makes library reusal preferable to implementation of given features in the verifier itself -- a bug in the verifier will can go unnoticed, while a bug in the library has much higher chance to be caught by the verifier itself.
Library reusal also keeps the verifier itself as small as possible, making it easier to ensure its correctness.
Sadly, the same aspect of library reusal increases the complexity of the
verification task, as the analysis tool now also has to analyse the code of the
library itself.
This can be especially a problem as the libraries are ususally performance-tuned making the code more complex to analyse.

An important point in library reusal is that libraries often take full advantage of the available language features.
Therefore, good support for the language is usually a prerequisite for library reuse.

It is also important to consider what degree of library reusal makes sence.
For example a C standard library uses low-level operating system API (such as
\texttt{sbrk} and \texttt{mmap} on on POSIX) to implement memory allocation.
It would therefore be possible to reuse the allocation implementation from a C
standard library implementation, provided this API was supported by the
verifier.
This, however, is probably not a good idea -- the OS level API provides large
blocks of memory which are then subdivided by the allocation functions, which
make it imposible to discern boundaries of different allocations or even if the
memory is allocated or freed without a detailed knowledge of the allocation
algorithm.
If the memory is instead provided in a seprated unit for each allocation it is
relatively easy to detect out-of-bouds accesses and access to freed memory.

Overall, we believe that reusal of (parts of) existing library implementations is crucial for good language support.
To the best of our knowedge, there are no program analysis tools which
re-implement libraries which have complete or nearly complete support of the
respective programming languages -- examples of these tools are
ESBMC++~\mcite{Ramalho2013} for C++ and JPF~\mcite{Artho2019} for Java, both of
which mention that they support only parts of the repsective standard
libraries.

\section{Component Reuse in DIVINE}\label{sec:lang:divine}

In DIVINE, we use the clang compiler to produce LLVM IR, which is then linked
with implementations of libraries and instrumented for the verification.
The LLVM IR with verification-specific instrumentation will be called \divm IR,
mathching the naming introduced by~\mcite{DIVINEToolPaper2017}.
\divm is the core of DIVINE which handles execution of LLVM in a memory-safe
way and is able to save and restore state of the execution.
The overview of this process can be seen in \autoref{fig:lang:divineworkflow}.

\begin{figure}[tp]
\center
\begin{tikzpicture}[ ->, >=stealth', shorten >=1pt, auto, semithick
                   , state/.style={ rectangle, draw=black, very thick,
                        minimum height=1.7em, inner ysep=2pt, inner xsep=0.5em,
                        text centered, node distance = 1.5em }
                   ]
  \node[state] (code) {C++ code};
  \node[state, right = 11.7em of code] (prop) {property and options};

  \node[state, below = 3.8em of code, rounded corners] (clang) {compiler};
  \node[state, right = of clang, rounded corners] (link) {linker};
  \node[state, below = 1.5em of link.south, anchor = north] (runtime) {libraries \& runtime};
  \node[state, right = of link, rounded corners] (lart) {instrumentation};
  \node[state, right = of lart.north east, anchor = north west, rounded corners, align = center] (verifier) {verification core\\(\divm)};
  \node[above = 0.5em of lart] (pverify) {};

  \node[state, below = 4.5em of verifier.south east, anchor = north east] (valid) {\color{green!40!black}Valid};
  \node[state, left = 1em of valid] (ce) {\color{red}Counterexample};

  \begin{pgfonlayer}{background}
      \node[state, fit = (pverify) (clang) (runtime) (lart) (verifier),
            inner sep = 0.6em, thick, rounded corners, dashed] (verify) {};
  \end{pgfonlayer}

  \node[above = 0.1em] at (verify.north) {DIVINE};

  \path (prop.348) edge[|*] (verifier.north)
        (prop.192) edge[|*] (lart.north)
        (code) edge (clang)
        (clang.north east) edge[bend left] node {LLVM IR} (link.north west)
        (runtime) edge[|*] (link.south)
        (link.north east) edge[bend left] node {LLVM IR} (lart.north west)
        (lart.north east) edge[bend left] node {\divm IR} (verifier.north west)
        (verifier.325) edge[|*] (valid.north)
        (verifier.215) edge[|*] (ce.north)
        ;
\end{tikzpicture}
\caption{Workflow of processing of a C++ program by DIVINE.
    Boxes with rounded corners represent stages of input processing.
}\label{fig:lang:divineworkflow}
\end{figure}

To make the compilation as easy as possible, the clang compiler is integrated
into DIVINE as a library, and the libraries which are linked with the program
are built at the time of built of DIVINE.
The original integration of clang into DIVINE 4 and the adaptation of LLVM
linker for use with DIVINE was done by me, with the work then taken over by
other memebers of the team.
The current state of the compilation for DIVINE is described in~\mcite{BR2020}.


In order to provide support for most of C and C++, DIVINE has to also provide
standard libraries for these languages.
DIVINE has support for the C and C++ standard libraries, and for the POSIX
thread library (\texttt{pthreads}), which is used on POSIX systems for
implementation of threading in C/C++ code prior to the 2011 standards and for
the implementation of the standard threading in the later versions of C/C++.
DIVINE also has support for many POSIX standard functions, including large parts of the filesystem API.

The threading library is written specifically for verfication with DIVINE --
indeed the whole idea of verification of parallel programs requires that that
at some level of the abstaction a verification-specific semantics of threads is
given.
In the case of DIVINE, \divm provides explicit nondeterministic choice
primitives, which are used by the core of DIVINE's runtime (\dios) to implement
thread spawning, which is in turn used by implementation of POSIX thread
library to start threads.
Mutexes, condition variables, and other syncronization primitives, which in
execution environment usually use operating system for the waiting and
signalling are implemented using atomic sections. 

Similarly to threading support, parts of the C standard library have to be
implemented specifically for the verifier.
In our case these parts are mostly memory allocation and deallocation, which
takes memory directly from \divm, program startup and exit which is \dios specific, and handling of the \texttt{errno} variable whic is also \dios specific.
The rest of the standard C library originates mostly from
PDClib~\mcite{TODO:pdclib}, with some parts from various other open-source C
library implementations and contributions from DIVINE developers.

The C++ standard library usually builds on top of a C standard library.
This allowed us to re-use existing implementation of C++ standard library,
namely the \texttt{libc++abi} (which takes care of low-level features such as
memory allocation and run-time type support, which can be viewed as part of the
language itself, but need a library implementation in practice) and
\texttt{libc++} (which represents all the user-facing features of the C++
standard library).
Both of these libraries are part of the LLVM project and used for example on
macOS and certain BSD flavours as the default C++ library implementations.
Reusing of these libraries takes care of most of the C++ features which require
library support, with the sole exception of exceptions, that require a special
library for stack manipulation -- an \emph{unwinder}.
The unwinder library used in DIVINE is \divm specific and is described,
together with more details about exception support in DIVINE in the next
section.
Nevertheless, by adhering to the interface of the unwiner library used normally
on POSIX systems, we were able to make use of all the exception handling code
in \texttt{libc++abi} without any changes to it.
The changes in the source code of \texttt{libc++} and \texttt{libc++abi} are limited to changes to platform configuration macros and in \texttt{libc++abi} there is a change in allocation of thread-local backup storage for exception handling.

The POSIX APIs, mainly concerning filesystem, are provided by \dios and were
implemented for use with \divine or other program analysis
tools~\mcite{RBMKB2019}.
This functionality makes it possible to analyze programs which use filesystem and other supported parts of POSIX, either with a simulated environment, or with recording and replay of interaction with real environment.

The library support and the situation concerning library reuse is summarized by \autoref{tab:lang:reuse}.

The libraries used for verification are shipped with DIVINE source code and
compiled into LLVM IR libraries at the time of compilation of DIVINE.
These LLVM IR libraries are then linked to the program at the time of its
compilation for DIVINE.
The verification workflow and the execution workflow are rather similar in the
case of DIVINE (especially on POSIX systems) -- the program is in both cases
compiled and then linked with an implementation of C and C++ standard
librarires, POSIX thread library, and an stack unwinder.

\begin{table}[tp]
  \begin{tabularx}{\textwidth}{>{\raggedright}p{5.5em}p{5.5em}L}
      \toprule
      Library    & Reused? & Comment \\\midrule\midrule
      C standard & mostly (\mbox{PDClib}, other) & Platform dependent code such as allocation, program startup and exit, \texttt{errno} cannot be reused without replicating too many details of the operating system. \\\midrule
      C++ standard & yes (\texttt{libc++}) & Only changes to of platform selection macros needed. \\\midrule
      C++ runtime  & yes (\texttt{libc++abi}) & Platform selection + tweak of backup allocator for exceptions (to prevent performance penalty) \\\midrule
      POSIX threads & no & Needs to be verification specific to allow exploration of all behaviours of a concurrent program. \\\midrule
      POSIX filesystem & no & Normally requires operating system support and cannot revert into previous state. Verified program should not access outside environment directly. \\\midrule
      stack unwinder & no & Platform specific (depends on stack layout and metadata format), cannot be reused without replicating too many details of the hardware platform. \\
      \bottomrule
  \end{tabularx}
  \caption{Summary of reusal and reimplementation of libraries in DIVINE.}\label{tab:lang:reuse}
\end{table}

\section{C++ Exceptions in DIVINE}\label{sec:lang:except}

Exceptions are among the features that are both widely used (including
by the standard library) and tricky to implement.
Their use is, however, also common outside of the standard library: libraries
like \texttt{boost} and application-level code often take advantage of this
capability.
This is natural, since exceptions simplify error handling and usually require
less boilerplate code than any of the alternatives.
Furthermore, even though many C++ standard library implementations can
be built without exception support\mnote{There are cases where not
  using exceptions makes sense: if the end-user code makes no use of
  them but the standard library is compiled with exception support, the
  requisite metadata tables only serve to increase the size of the
  compiled program.}, this change can significantly affect its behaviour
(and as such, validity of the verification result).
Finally, error handling paths, including exception propagation, are an
important target for analysis by verification tools, as they are both hard to
test by more conventional means and likely to contain errors -- this naturally
arises from the fact that their purpose is to handle unlikely side cases which
can be hard to accurately reproduce with testing.
A model checker, on the other hand, can take advantage of its built-in support
for non-determinism to rigorously explore error paths.\mnote{This is a
  form of fault injection. When using a model checker, it is only necessary to
  modify the function where the error may arise (e.g.~the \cpp{malloc}
  function may be modified to return a \cpp{NULL} pointer
  non-deterministically). The model checker will then take care of exploring
  all possible combinations of succeeding and failing memory allocations in the
  program.}

\subsection{Contribution}\label{contribution}

The apporach to exception support described in this section, and originally published in \mcite{SRB2017} bringhs the following contributions:
first, we identify the
components that are best re-used and those which are best re-implemented
and show that this decision crucially depends on the underlying
intermediate language. Second, we provide implementations of the
components which cannot be re-used in a form that is easy to integrate
into both existing and future verification tools. One of the components
works as an \llvm{} transformation pass, and could be used with any
\llvm{}-based tool. The other component targets the \divm{}
language~\mcite{RSCB2018} specifically, and will therefore only
work with tools which understand this language.\mnote{\divm{} is a
  relatively small extension of the \llvm{} IR, therefore extending tools
  which work with pure \llvm{} to also support \divm{} may be quite easy.}

The goal of this work, especially in the context of our previous work
on the topic of C++ exceptions in
verification~\mcite{RBB16}, is to aid authors of
verification tools to minimise costs and effort associated with
inclusion of exception support. Depending on the characteristics of the
tool, either the approach described in~\mcite{RBB16} or
the one in this paper might be more suitable. Overall, in a verifier
which can handle the \divm{} language or equivalent, the approach given in
this paper is simpler to implement and more robust. A more detailed
comparison of the two approaches is given in \autoref{sec:lang:cmpD3}.

All source code related to this work, along with more detailed
benchmark results and other supplementary material, are available online
under a permissive open-source licence.\mnote{\url{https://divine.fi.muni.cz/2017/exceptions}}
The implementation is also fully integrated part of the DIVINE model checker
and therefore present in its current versions.

\subsection{Components for Exception Support}

Unlike other features of C++, exceptions are neither handled by the
standard or runtime libraries alone, nor delegated to the C standard
library (as C has no support for exceptions). Instead,
\texttt{libc++abi} provides exception support with the help of a
platform-specific \emph{unwinder library} which is responsible for stack
introspection and unwinding (removal of stack frames and transfer of
control to exception-handling code).

For this reason, \divine{} has to either provide an unwinder implementation
compatible with \texttt{libc++abi}, or modify \texttt{libc++abi} to use
custom code for exception handling. In \divine{} 3, the latter approach was
used, as it was deemed easier at the
time~\mcite{RBB16}. However, while basic exception
support was easier to achieve this way, the approach also had its
disadvantages. First, the \llvm{} interpreter in \divine{} 3 had special
support for exception-related functionality. Second, the
\texttt{libc++abi} code for exception handling was replaced, which had 2
important consequences: first, the replacement code was not
comprehensive enough\mnote{That is, some of the less frequently used
  features of C++ exceptions were handled either incorrectly or not at
  all. That is to say, the size of the \texttt{libc++abi} portion that
  would have needed to be re-implemented was initially underestimated.}
and second, this meant that the replaced part of \texttt{libc++abi} was
not taken into account during verification.

In this work, we instead take the first approach: reuse
\texttt{libc++abi} in its entirety and provide the interfaces it
requires. Therefore, we have implemented the \texttt{libunwind}
interface used by \texttt{libc++abi} for stack unwinding and an \llvm{}
instrumentation which builds metadata tables that \texttt{libc++abi}
needs to decide which exceptions should be caught, how they should be
handled and which functions on the stack need to perform cleanup
actions.
To put this into perspective, the code which drives exception handling in \texttt{libc++abi} is about 1300 lines of code, while the code related to \texttt{libunwind} implementation in DIVINE is about 210 lines and the instrumentaton for C++ specific metadata is about 300 lines of code.

Using the original \texttt{libc++abi} code means that all features of
the C++ exception system are fully supported and verification results
also cover the low-level exception support code. That is, this portion
of the code is identical in both the bitcode which is verified and in
the natively executing program.\mnote{Clearly, the \texttt{libunwind}
  implementation is different in those two environments, and therefore
  correctness of the platform-specific implementation of
  \texttt{libunwind} must be established separately.}
Furthermore, should the need arise to use different C++ runtime library then
\texttt{libc++abi} (for example to provide additional guarantees for programs
which use this different library), our solution should work without any
modification of the given C++ runtime library, provided it uses the
(semi-standard) unwinder interface.
Finally, proposed design is easier to extend to other programming
languages as the \texttt{libunwind} implementation is generic and language
independend and only the instrumentation which provides language-specific
metadata needs to be provided to different languages.

\section{Exceptions in C++}\label{sec:exceptions}

The process of exception handling in C++ is illustrated by \autoref{fig:lang:exceptcpp}.

\begin{figure}[tp]
  \begin{cppcode}
    int max(std::vector<int> &vec) {
      if (vec.empty())
        throw std::invalid_argument("empty vector");
      /* ... */
    }
    void foo() {
      std::vector<int> a = { 1, 2, 3 };
      std::vector<int> b = {};
      auto x = max(b);
      /* ... */
    }
    int main() {
      try {
        foo();
      }
      catch (std::range_error &) {
        std::cout << "range error\n";
      }
      catch (std::invalid_argument &) {
        std::cout << "invalid argument\n";
      }
    }
  \end{cppcode}
\caption{Exception handling in C++ (with the zero-cost exceptions).
  A the moment the execution is thrown in \texttt{max}, there are three frames
  on the stack \texttt{max}, \texttt{foo}, and \texttt{main}.
  The exception can be caught by \texttt{main}, but the first the cleanup code
  in \texttt{foo} has to be executed -- this code will deallocate memory owned
  by the vectors present in this function.
  Therefore, first only the stack frame of \texttt{max} is removed and the
  cleanup in \texttt{foo} is executed.
  After the cleanup, the stack frame of \texttt{foo} will be removed from
  stack.
  Finally in \texttt{main} the unwinder will transfer control to the second
  catch statement.
}\label{fig:lang:exceptcpp}
\end{figure}

Throwing an exception requires removal of all the stack frames\mnote{The
execution stack of a (C++) program consists of stack frames, each holding
context of a single entry into some function. It contains local variables, a
return address and register values which need to be restored upon return.}
between the throwing and catching function from the stack (\emph{unwinding}).
Therefore, exception handling is closely tied to the particular platform and is
described by ABI\mnote{\emph{Application Binary Interface}, a low-level
interface between program components on a given platform.} for the platform.
Commonly, exception handling is split into two parts, one which is tied to the
platform (the \emph{unwinder library} which handles stack unwinding) and one
which is tied to the language and provided by the language's runtime
library.\mnote{There are many implementations of the C++ runtime
  library, which, besides exception support code, provides additional
  features such as RTTI.
  Each implementation is usually tied to a particular implementation of C++
  standard library.
  Commonly used implementations on Unix-like systems are \texttt{libsupc++},
  which comes with \texttt{libstdc++} and the GCC compiler, and
  \texttt{libc++abi}, which is tied to \texttt{libc++} used by some builds of
  clang and by \divine{}.}
These two parts cooperate in order to provide exception handling for a
given language; however, this communication is not standardised in any
cross-platform fashion.
For this reason, we will now focus on zero-cost exceptions based on the Itanium
ABI, an approach which is used across various Unix-like systems on \texttt{x86}
and \texttt{x86\_64} processor architectures and is the preferred basis for
\llvm{} exceptions.
Nevertheless, it is possible to generalize our results to other
implementations.

\subsection{Zero-Cost Exceptions}\label{sec:lang:zerocost}

The so-called zero-cost exceptions are designed to incur no overhead
during normal execution, at the expense of relatively costly mechanism
for throwing exceptions. This in particular means that no checkpointing
is possible. Instead, when an exception is thrown, the exception support
library, with the help of \emph{unwind tables}, finds an appropriate
\emph{handler} for the exception and uses the \emph{unwinder} to
manipulate the stack so that this handler can be executed. The search
for the handler is driven by a \emph{personality function}, which is
provided by the implementation of the particular programming language
and associated in the metadata with each function which can participate in exception handling.

The personality function is responsible for deciding which handler
should execute (the handler selection can be complex and
language-specific). In general, there are two types of handlers,
\emph{cleanup handlers}, which are used to clean up lexically scoped
variables (and call their destructors, as appropriate) and \emph{catch
handlers}, which contain dedicated exception-handling code. The latter
typically arise from \texttt{catch} blocks. Another major difference
between those two types of handlers is that catch handlers stop the
propagation of the exception, while cleanup handlers let propagation
continue after the cleanup is performed. While cleanup handlers are
usually run unconditionally, the catch handler to be executed, if any,
is determined by the personality function.\mnote{In fact, the
  personality function can also decide to skip cleanup handlers, but
  this is not common.} In C++, the personality function selects the
closest \texttt{catch} statement which matches the thrown type (the
match is determined dynamically, using RTTI). The personality function
consults the unwind tables, in particular their \emph{language-specific
data area (LSDA)}, to find information about the relevant catch
handlers.

When an exception is thrown, the runtime library of the language creates
an \emph{exception object} and passes it to the unwinder library. The
actual stack unwinding is, on platforms which build on the Itanium ABI,
performed in two phases (\emph{two phase handler lookup}).
First, the stack is inspected (without
modification) in search for a catch handler. Each stack frame is
examined by the relevant personality function.\mnote{Different
  personality functions can be called for different frames, for example
  if the program consists of code written in different languages with
  exception support.} If an appropriate catch handler is found in this
phase, unwinding continues with a second phase; otherwise, an unwinder
error is reported back to the throwing function. Unwinder errors usually
cause program termination. In the second phase, the stack is examined
again, and a personality function is invoked again for each frame. In
this phase, cleanup handlers come into play. If any handler is found
(cleanup or catch), this fact is indicated to the unwinder, which
performs the actual unwinding to the flagged frame. Once the control is
transferred to the handler, it can either perform cleanup and resume
propagation of the exception, or, if it is a catch handler, end the
propagation of the exception. If exception propagation is resumed, the
unwinder continues performing phase 2 from the point of the last
executed handler. This is facilitated by storing the state of the
unwinder within the exception object.

\subsection{Unwind Tables}\label{sec:lang:unwind-tables}

As mentioned in \autoref{sec:lang:zerocost}, both the unwinder library
and the language runtime depend on unwind tables for their work. The
unwinder uses these tables to get information about stack layout in
order to be able to unwind frames from it, and for detection which
personality function corresponds to a frame. The personality function
then uses the language-specific data area (LSDA) of these tables in its
decision process.

While the unwinder part of the tables is unwinder- and platform-specific
(it depends on stack layout), the LSDA is platform- and
language-specific. For these reasons, unwind tables are not present in
the \llvm{} IR; instead, they are generated by the appropriate code
generator for any given platform, based on information in the
\texttt{landingpad} instructions, and the personality attribute of
functions. On Unix-like systems, the unwind tables are in the
DWARF\mnote{DWARF is a standard for debugging information designed
  for use with ELF executables. It is used on most modern Unix-like
  systems.} format.

\section{Execution of \llvm{} programs}\label{sec:execution}

In this section, we will look at how \llvm{} bitcode is executed by a model
checker and how this execution is affected by addition of exception
support. Unlike previous approaches, the technique described in this
paper does not require any exception-specific intrinsic functions or
hypercalls to be supported by the verifier. The exception-specific \llvm{}
instructions can be implemented in the simplest possible way:
\texttt{invoke} becomes equivalent to a \texttt{call} instruction
followed by an unconditional branch. The \texttt{landingpad} instruction
can be simply ignored by the verifier and \texttt{resume} instructions
and calls of the \texttt{llvm.eh.typeid.for} intrinsic are both removed
by the LLVM transformation and instrumentation described in
\autoref{sec:lang:transform}.
Moreover, the metadata required by \texttt{libc++abi} are likewise
generated by the \llvm{} transformation and this process is completely
transparent to the verifier.

In addition to support for \llvm{}, the unwinder (described in more detail
in \autoref{sec:lang:unwinder}) requires the ability to traverse and
manipulate the stack and read and write \llvm{} registers associated with a
given stack frame. Finally, it needs access to a representation of the
bitcode for a given function. All those abilities are part of the \divm{}
specification~\mcite{RSCB2018} and are generally useful, regardless
of their role in exception support.

The \divm{} implementation in \divine{} 4 handles execution of \llvm{}
instructions, \llvm{} intrinsic functions and \divm{}-specific
\emph{hypercalls}.\mnote{Intrinsic functions are provided by \llvm{} as
  a light-weight alternative to new instructions. Such functions are
  recognized and translated by \llvm{} itself, as opposed to ``normal''
  functions that come from libraries or the program. Likewise, \divm{}
  provides hypercalls, which are functions that are, in addition to \llvm{}
  intrinsics, recognized by \divm{}.} Hypercalls exist to allocate memory,
perform nondeterministic choice or to set \divm{}'s \emph{control
registers} (which contain, among other, the pointer to the currently
executing stack frame). Additionally, \divm{} performs safety checks, such
as memory bound checking, and detects use of uninitialised values.
However, \divm{} hypercalls are intentionally low-level and simple and do
not provide any high-level functionality, such as threading or standard
C library functionality. Instead, those are provided by the \divine{}
Operating System (\dios{}) and the regular C and C++ standard libraries.

The most important purpose of \dios{} is to provide threading support. To
this end, \dios{} provides a \emph{scheduler}, which is responsible for
keeping track of threads and their stacks and for (nondeterministically)
deciding which thread should execute next. This scheduler is invoked
repeatedly by the verifier to construct the state space. The scheduler
fully determines the behaviour (or even presence) of concurrency in the
verified program: while \dios{} provides asynchronous, preemptive
parallelism typical of modern operating systems by default, it has also support
for a synchronous scheduler and it would be possible to implement a
cooperative scheduler too.

\subsection{Stack Layout and Control Registers}\label{sec:lang:stack-layout}

A \divm{} program can have multiple stacks, but only one of them can be
active at any given time (a pointer to the active stack is kept in a
\divm{} control register). The active stack is normally either the kernel
stack or the stack that belongs to the active thread which was selected
by the scheduler. Switching of stacks (and program counters) is
performed by the \texttt{control} hypercall which manipulates \divm{}
control registers.

Traditionally, stack is represented as a continuous block of memory
which contains an activation frame for each function call. In \divm{}, the
stack is not continuous; instead, it is a singly-linked list of
activation frames, each of which points to its caller. This has multiple
advantages: first, it is easy to create a stack frame for a function,
for example when \dios{} needs to create a new thread; additionally, the
linked-list-organized stack is a natural match for the graph
representation of memory which \divm{} mandates, and therefore can be saved
more efficiently~\mcite{RSCB2018}. Additionally, this way the stack
may be nonlinear, and the unwinder can use this feature to safely
transfer control to a cleanup block while the unwinder frame is still on
the stack. Later, the handler can return control to the unwinder frame
and the unwinder can continue its execution. This would be impossible
with a continuous stack since cleanup code is allowed to call arbitrary
functions and frames of those functions would overwrite the frame of the
unwinder. For this reason, on traditional platforms, the unwinder needs
to store its entire state in the exception object, while in \divm{}, it can
simply retain its own activation frame, which simplifies the unwinder.
An illustration of how the stack looks while the unwinder is active is shown in
\autoref{fig:lang:treestack}.

\begin{widefigure}
\centering
\begin{tikzpicture}[ ->, >=stealth', shorten >=1pt, auto, node distance=3cm
                   , semithick
                   , common/.style={rectangle, draw=black, inner sep=2pt,
                                    node distance = 0em}
                   , framepart/.style={common, minimum height=1.7em,
                                       minimum width = 9.2em, text centered} 
                   , vmreg/.style={common, minimum height=2em, minimum width = 4em}
                   , frame/.style={matrix of nodes, nodes={framepart},
                                   node distance = 1em}
                   , box/.style={draw, dashed, rounded corners}
                   ]

    \matrix[matrix of nodes, nodes={vmreg}] (vmreg) {
        \strut … &
        \strut PC &
        \strut frame &
        \strut …\\};
    \node[above = 0 of vmreg.north, anchor = south] (vmreg-l) {VM Registers};
    \node[box, fit = (vmreg) (vmreg-l)] {};

    \matrix[frame, below left = 4em and -2em of vmreg] (close) {%
        \cpp{close()} \\
        caller \\
        PC = … \\
        …\\};

    \matrix[frame, below = of close] (dFile) {%
        \cpp{~File()} \\
        caller \\
        PC = \li{call @close} \\
        … \\};

    \matrix[frame, below = of dFile] (main) {%
        \cpp{main()} \\
        caller \\
        PC = \li{call}\texttt{ @\textasciitilde{}File} \\
        … \\
        exception \\
        … \\};

    \matrix[frame, below = of main] (start) {%
        \cpp{_start()} \\
        caller = \cpp{NULL} \\
        PC = \li{call @main} \\
        … \\};

    \node[above = 0 of close.north, anchor = south] (pstack-l) {Program Stack};
    \node[box, fit = (pstack-l) (close) (dFile) (main) (start)] {};

    \matrix[frame, nodes={minimum width=13em}, right = 5em of close] (unwind) {%
        \cpp{_Unwind_RaiseException()} \\
        caller \\
        PC = … \\
        … \\};

    \matrix[frame, nodes={minimum width=18em}, below = of unwind] (throw) {%
        \cpp{__cxa_throw()} \\
        caller \\
        PC = \li{call @_Unwind_RaiseException} \\
        … \\};

    \node[above = 0 of unwind.north, anchor = south] (uwstack-l) {Unwinder Stack};
    \node[box, fit = (uwstack-l) (unwind) (throw)] {};

    \matrix[frame, nodes={minimum width=14em}, below = 7em of throw] (exception) {%
        exception object \\
        exception class = \texttt{0x}… \\
        … \\
        private\_1 \\
        private\_2 = \li{landingpad} … \\
        … \\
        C++ Exception Object \\};
          
    \draw (vmreg-1-3) edge[out=220, in=47] (close)

        (close-2-1.east) edge[bend left] (dFile-1-1.east)
        (dFile-2-1.east) edge[bend left] (main-1-1.east)
        (main-2-1.east) edge[bend left] (start-1-1.east)

        (throw-2-1.west) edge[out=180, in=0] (main-1-1.east)
        (unwind-2-1.east) edge[bend left] (throw-1-1.6)

        (exception-4-1.east) edge[out=45, in=-45] (unwind-1-1.east)
        (main-5-1) edge[out=0, in=180] (exception-1-1.west)
      ;
\end{tikzpicture}
\caption{In this figure we can see a stack of a program which is running
cleanup block in the \texttt{main} function. The cleanup block calls the
destructor of \texttt{File} structure, which in turn calls the
\texttt{close} function (which is the current active function).
Furthermore, the cleanup handler can access the exception object which
contains a pointer to the stack of the unwinder (and the program counter of the catch block).
The frame pointer in the exception is used by the implementation of the
\texttt{resume} instruction to jump back to the unwinder and continue phase 2
of the unwinding.
}\label{fig:lang:treestack}
\end{widefigure}

\section{The \llvm{} Transformation}\label{sec:lang:transform}

The C++ runtime library (\texttt{libc++abi} in our case), needs access
to the LSDA section of unwind tables (a pointer to this metadata section
is accessible through the unwinder interface). This section contains
DWARF-encoded exception tables, which are normally generated together
with the executable by the compiler backend (code generator).
Unfortunately, the generator of DWARF exception tables in \llvm{} is
closely tied to the machine code generator and cannot be used to
generate DWARF-formatted exception tables for the \llvm{} IR used for
verification purposes.
For
this reason, we have implemented a small \llvm{} transformation which
processes the information in \texttt{landingpad} instructions and
generates \llvm{} constants which contain the DWARF-formatted LSDA data. A
reference to one such constant is attached to each function in the
bitcode file.

The choice of catch block in C++ depends on the actual type the exception has
at runtime.
This type can be inspected thanks to run-time type information (RTTI).
The RTTI can also be used to determine if one class inherits from other class,
which is needed to decide which catch block can be used (as catch blocks can
catch exceptions of derived types).
The RTTI is avaible through RTTI type info pointers, special C++ objects which
are used to identify types at runtime and are emitted by the C++ frontend as
constants. 
Type info pointers can be obtained from an object using the \texttt{typeof}
operator in C++ and in \llvm{} they are saved in the virtual member functions'
table (\emph{vtable}; for objects which have virtual member functions, other
objects do not have RTTI type info pointers saved in them and the corresponding
type info is fully determied by their static type).

To improve efficiency, \llvm{} and zero-cost exceptions do not directly use
RTTI type info pointers within the landing blocks to decide which exception
handlers should run.
Due to the complexities of C++ type system, matching RTTI
types against each other is expensive: a search in a pair of directed
acyclic graphs is required. Moreover, since the RTTI matching must be
already done in the personality function to decide which frames to
unwind, the personality can also pre-compute a numerical index for the
landing pad. This index, also called a \emph{selector value} is then
used as a shortcut to run an appropriate \texttt{catch} clause within
the landing block, instead of re-doing the expensive RTTI matching.
Since the \texttt{catch} handler is typically expressed in terms of
typeinfo pointers, it needs to efficiently obtain the selector value
from a type info pointer. For this purpose, \llvm{} provides a
\texttt{llvm.eh.typeid.for} intrinsic, which obtains (preferably at
compile time) the selector value corresponding to a particular type info
pointer.

Therefore, besides generating the LSDA data, the transformation
statically computes the values of
calls to \texttt{llvm.eh.typeid.for} and substitutes them into the bitcode.
The purpose of \texttt{llvm.eh.typeid.for} is to translate from
RTTI pointers to selector values, therefore it is only required that the integer
selector value chosen for a particular RTTI object is in agreement with
the personality function. In our implementation, this is ensured by
computing the selector values statically for both the LSDA (which is
where personality function obtains them) and for
\texttt{llvm.eh.typeid.for} at the same time.

Finally, the transformation rewrites all uses of the \texttt{resume}
instruction to ordinary calls to \texttt{Resume}, a function which is
part of \texttt{libunwind} (see also \autoref{tbl:lang:libunwind}).

\section{The Unwinder}\label{sec:lang:unwinder}

The unwinder in \divine{} is designed around the interface described in the
Itanium C++ ABI documentation,\mnote{\url{https://mentorembedded.github.io/cxx-abi/abi.html}}
adopted by multiple vendors and across multiple architectures. The
implementation is part of the runtime libraries shipped with
\divine{}, in particular in file \texttt{dios/arch/divm/unwind.cpp}.
The
unwinder builds upon a lower-level stack access API which is provided by
\dios{} under \texttt{dios\slash{}include\slash{}sys\slash{}stack.h} and implemented in \texttt{dios\slash{}arch\slash{}divm\slash{}stack.cpp}.

\begin{table}[tp]
\caption{A list of C functions provided by \texttt{libunwind}. In C, all the
functions are prefixed with \texttt{\_Unwind\_} to prevent name conflicts with
user code and other libraries (i.e.~the C name of \texttt{SetGR} is
\texttt{\_Unwind\_SetGR}). }\label{tbl:lang:libunwind}

\begin{tabularx}{\textwidth}{lL}
\toprule
Function & Description\\
\midrule
\texttt{SetGR} & Store a value into a general-purpose register\\
\texttt{GetGR} & Read a value from a general-purpose register\\
\texttt{SetIP} & Stora a value into the program counter\\
\texttt{GetIP} & Read the value of the program counter\\
\texttt{RaiseException} & Unwind the stack\\
\texttt{Resume} & Continue unwinding the stack after a cleanup\\
\texttt{DeleteException} & Delete an exception object (free its resources)\\
\texttt{GetLSDA} & Obtain a pointer to the LSDA\\
\texttt{GetRegionStart} & Obtain a base for relative code pointers\\
\bottomrule
\end{tabularx}
\end{table}

Due to the stack layout used in \divm{} (a linked list of frames, see also
\autoref{sec:lang:stack-layout}), our unwinder is much simpler than
usual. The main task of unwinding is handled by the
\texttt{RaiseException} function, which is called by the language
runtime when an exception is thrown. This function performs the two
phase handler lookup described in \autoref{sec:lang:zerocost} and it
adheres to the Itanium ABI specification, with the following exceptions:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\item
  it checks that an exception is not propagated out of a function which
  has the nounwind attribute set, and reports verification error if this
  is the case;
\item
  if the exception is a C++ exception and there is no handler for this
  exception type, the unwinder chooses nondeterministically whether it
  should or should not unwind the stack and invoke cleanup handlers.
\end{enumerate}

The purpose of the first deviation is to check consistency of exception
annotations (arising, for example, from a \texttt{nothrow} function
attribute as available in GCC and in clang). The second modification
allows \divine{} to check both allowed behaviours of uncaught exceptions in
C++: the C++ standard specifies that it is implementation-defined
whether the stack is unwound (and destructors invoked) when an exception
is not caught.\mnote{Section~15.5, paragraph 9~of the C++
  \TODO{standard~\cite{cxx14:standar.program}}} Since the program may contain
errors which manifest only under one of these behaviours, it is useful
to be able to test both of them.

\subsection{Low-Level Unwinding}\label{sec:unwinder:ll}

The primary function of the unwinder described above is to find
exception handlers; for the actual unwinding of frames, it uses a
lower-level interface provided by \dios{}. This interface consists of two
functions: \texttt{\_\_dios\_jump}, which performs a non-local jump,
possibly affecting both the program counter and the active frame, and
\texttt{\_\_dios\_stack\_free}, which removes stack frames from a given
stack. \texttt{\_\_dios\_stack\_free} is designed in such a way that it can
unwind any stack, not only the one it is running on, and is not limited
to the topmost frames (effectively, it removes frames from the stack's
singly-linked list, freeing all the memory allocated for local variables
that belong to the unlinked frames, along with the frames
themselves\mnote{When a function returns normally (due to a
  \texttt{ret} instruction), \divm{} takes care of freeing the frame and
  its local variables (\texttt{alloca} memory).}). The unwinder
identifies values as local variables by looking at the instructions of
the active function -- the results of \texttt{alloca} instructions are
exactly the addresses of local variables.

\subsection{Unwinder Registers}\label{unwinder-registers}

When an exception is propagating, a personality function has to be able
to communicate with the code which handles the exception. In C++, the
communicated information includes the address of the exception object
and a selector value which is later used by the handler. On most
platforms, these values are passed to the handler using registers, which
are manipulated using unwinder's \texttt{SetGR} function. This function
can either set the register directly (if it is guaranteed not to be
overwritten before the control is transferred to the handler), or save
the value in a platform-specific way and make sure it is restored before
the handler is invoked.

In \llvm{} (and hence in \divm{}), there is no suitable counterpart to the
general purpose registers of a CPU; instead, the values set by the
personality function should be made available to the program in the
return value of the \texttt{landingpad} instruction. This, however,
requires the knowledge of the expected semantics of these registers.
Currently, all users of the unwinder are expected to use the same
registers as the C++ frontend in clang. That is, register 0 corresponds
to the exception object and register 1 corresponds to a type index. This
also directly maps to the return type of \texttt{landingpad}
instructions and therefore the register values can be saved directly
into the \llvm{} register corresponding to the particular
\texttt{landingpad} that is about to be executed.

Registers other than 0 and 1 are currently not supported. In \llvm{}, in
line with the above observation about clang and C++, there is a
convention that \texttt{SetGR} indices correspond to indices into the
result tuple of a \texttt{landingpad} instruction. As long as this
convention is preserved by a particular language frontend and its
corresponding runtime library (personality function), it is very easy to
extend our unwinder to support this language. Finally, if a language
frontend were instead to emit calls to \texttt{GetGR} in the handler,
registers of this type can be stored in the unwinder \texttt{Context}
directly.

\subsection{Atomicity of the Unwinder}\label{atomicity-of-the-unwinder}

The unwinder performs rather complex operations and therefore throwing
an exception can create many states, even when $\tau$
reduction~\mcite{RBB13} is enabled. However, many of
these states are not interesting from the point of view of verification,
as the operations performed by the unwinder are mostly thread-local and
only the exception handlers (and possibly personality function) can
perform globally visible actions. For this reason, the unwinder uses
\dios{} atomic sections to hide most of its complexity.

Since an atomic section is implemented as an \emph{interrupt mask}
(i.e.~a single flag indicating that an atomic section is executing) in
\divm{}'s flag register, it is necessary to correctly maintain the state of
this flag.
In
particular, it is required that the unwinder behaves reasonably even if
it is called when the program is already in an atomic section.
Consequently, care must be taken to restore the state of the atomic mask
when the unwinder transfers control to a personality function or an
exception handler. When the unwinder is first called, it enters an
atomic section and saves the previous value of the interrupt mask. This
will be the value the flag will be restored to when a personality
function is first invoked. The mask is later re-acquired after the
personality function returns and it is restored once more when the first
handler is invoked. When the exception handler resumes (using the
\texttt{resume} instruction), the atomic section is re-entered and its
state saved so its state before the resume can be restored again for the
next call to a personality function. This way, it is possible to safely
throw an exception out of an atomic section, provided that the atomic
section is exception-safe (that is, it has an exception handler which
ends the atomic section if an exception is propagated out of it).
This is a reasoneble assumption because atomic sections are mostly used in the
implementation of \dios itself, and they should use C++ guard objects to ensure
exception safety.

\subsection{\texorpdfstring{\texttt{longjmp} Support}{longjmp Support}}\label{sec:lang:longjmp-support}

Using the low-level unwinder interface described in
\autoref{sec:unwinder:ll}, it is easy to implement other mechanisms
for non-local transfer of control. The functions \texttt{longjmp} and
\texttt{setjmp}, specified as part of C89, are one such
example.\mnote{Implemented in \texttt{dios/includes/setjmp.h}
  and \texttt{dios/libc/setjmp/}.}
The \texttt{setjmp}
function can be used to save part of the state of the program, so that a
later call to \texttt{longjmp} can restore the stack to the state it was
in when \texttt{setjmp} was called. This way, \texttt{longjmp} can be
used to remove multiple frames from the stack. When \texttt{longjmp} is
called, the program behaves as if \texttt{setjmp} returned again, only
this time it returns a different value (provided as an argument to
\texttt{longjmp}).

The \divine{} implementation of \texttt{setjmp} saves the program counter
and the frame pointer of the caller of \texttt{setjmp}.
The \texttt{longjmp} function then uses this saved state, along with access to
metadata about stack frames, to set the return value of the \texttt{call}
instruction corresponding to the \texttt{setjmp}.
Afterwards, it unwinds the stack using the low-level stack access API and
transfers control to the instruction right after the call to \texttt{setjmp}.

\section{Related Work}\label{sec:lang:related}

Primarily, we have looked at existing tools which support verification
of C++ programs. Existence of an implementation is, to a certain degree,
an indication that a given approach is viable in practice. We have,
however, also looked at approaches proposed in the literature which have
no implementations (or only a prototype) available.

A number of verification tools are based on \llvm{} and therefore have some
support for C++. LLBMC~\cite{Falke2013} and
NBIS~\cite{Gunther2014} are \llvm{}-based bounded model
checkers which target mainly C and have no support for exceptions or the
C++ standard library. VVT~\cite{Gunther2016} is a
successor of NBIS which uses either IC3 or bounded model checking and
has limited C++ support, but it does not support exceptions.
Furthermore, KLEE~\cite{Cadar2008} and KLOVER~\cite{Li2011}
are \llvm{}-based tools for test generation and symbolic execution. KLOVER
targets C++ and according to~\cite{Li2011} has exception support,
but it is not publicly available. On the other hand, KLEE focuses
primarily on C and its C++ support is rather limited.
As of April 2020 there is ongoing work on exception support in KLEE.

Both CBMC~\cite{Clarke2004}, \cite{Kroening2014} and
ESBMC~\cite{Gadelha2018} bounded model checkers support C++
(but neither appears to support the standard library) and they appear to have some
support for exceptions.
However, in CBMC, the support for exceptions seems to be limited to recognition
of the \cpp{try-catch} syntax, but throwing an exception triggers an error.\mnote{A
simple test which throws and tries to catch an exception object crashes CBCM
5.11 during verification and a code which attempts to catch exception by
referrence (which is the recommended pracice in C++) results in spurious syntax error during program parsing.}
\TODO{
In our survey of tools for verification of C++ programs, ESBMC
has by far the best exception support: the latest version can deal with
most, but not all\mnote{ESBMC 3.0 is unable to determine that an
  exception ought to be caught when the \cpp{catch} clause specifies
  a type which is a virtual base class in a diamond-shaped hierarchy and
  the object thrown is of the most-derived type of the diamond. This
  suggests that ESBMC uses its own implementation of RTTI support code,
  which is somewhat incomplete, compared to production implementations.},
types of exception handlers and even with exception specifications.
}
Finally, \divine{} 3~\cite{RBB16} also comes close to
full support for exceptions, but lacks support for exception
specifications. Overall, this survey suggests that all current
implementations of C++ exceptions in verification tools are incomplete
and confirms that using an existing, standards-compliant implementation
in a verification tool is indeed quite desirable.

Finally, it is also possible to transform a C++ program with exceptions
into an equivalent program which only uses more traditional control flow
constructs. This approach was taken in~\cite{Prabhu2011},
with the goal of re-using existing analysis tools without exception
support. While this approach is applicable to a wide array of
verification tools, it is also incompatible with re-use of existing
exception-related runtime library code. As such, it offers a very
different set of tradeoffs than our current approach. Moreover, the
translation cost is far from negligible, and also affects code that does
not directly deal with exceptions (i.e.~it violates the zero-cost
principle of modern exception handling). Unfortunately, we were unable
to evaluate this approach, since there are no publicly available tools
which would implement it.

\section{Evaluation}\label{sec:lang:evaluation}

In order to asses the viability of our approach, we have executed a set
of benchmarks in various configurations of \divine{}~4. The benchmarks were
executed on quad-core Xeon 5130 clocked at 2 GHz and with 16GB of RAM.
We have measured the wall time, making all 4 cores available to the
verifier.

\subsection{Benchmark Models}\label{benchmark-models}

The set of models we have used for this comparison consists of 831 model
instances, out of which we picked the 794 that do not contain errors.
The reason for this is that the execution time is much more variable
when a given program contains an error, since the model checking
algorithm works on the fly, stopping as soon as the error is discovered and
explores the state space in parallel, which makes the exploration order vary
between verification runs.

Majority of the valid models (777) are C++ programs of varying
complexity, while the 17 models in the svc-pthread category are
concurrent programs written in plain C with pthreads. Since our
implementation of the POSIX thread API is done in C++, the impact of
exception support on verification of C programs is also relevant. The
``alg'' category includes sequential algorithmic and data structure
benchmarks, the ``pv264'' category contains unit tests for student
assignments in a C++ course, the ``iv112'' category contains unit tests
for concurrent data structures and other parallel programs (again assignment
problems in a course about concurrency in C++), ``libcxx'' contains a selection
of tests from
the \texttt{libc++} testsuite (with focus on exception support
coverage), ``bricks'' contains unit tests for various C++ helper
classes, including concurrent data structures, ``divine'' contains unit
tests for a concurrent hashset implementation used in \divine{},
``cryptopals'' contains solutions of the cryptopals problem
set\mnote{\url{http://cryptopals.com}}, the ``llvm'' category
contains programs from the \llvm{} test-suite\mnote{\url{http://llvm.org/svn/llvm-project/test-suite/trunk/SingleSource/Benchmarks/Shootout}}
and finally, the ``svc-pthread'' category includes pthread-based C
programs from the SV-COMP benchmark set. In most of the programs, it was
assumed that \texttt{malloc} and \texttt{new} never fail, with the
notable exception of part of the ``bricks'' category unit tests. The
tests where \texttt{new} failures are allowed are especially suitable
for evaluating exception code, in particular if multiple concurrent
threads are running at the time of the possible failure.

\subsection{Comparison to Builtin Exception Support}\label{sec:lang:cmpD3}

In addition to the approach presented in this paper, we have implemented
the approach described in~\mcite{RBB16} in the context
of \divine{}~4. This allowed us to directly measure the penalty associated
with the present approach, which is more thorough and less
labour-intensive at the same time. Our expectation was that this would
translate to slower verification, since the off-the-shelf code is more
complex than the corresponding hand-tailored version used
in~\mcite{RBB16}. In line with this expectation, we set
the criterion of viability: we would consider a slowdown of at most
10\,\% to be an acceptable price for the improved verification fidelity,
and convenience of implementation. Since other resource consumption
(especially memory) of verification is typically proportional to state
space size, we have used the number of states explored as an additional
metric. The expected effect on the shape (and, by extension, size) of
the state space should be smaller than the effect on computation time
(most of the additional complexity is related to computing a single
transition). We believe that an acceptable penalty in this metric would
be about 2\,\% increase.

\begin{table}[tp]
\caption{\label{tbl:D4D3}Comparison of the new exception code with a
\divine{}-3-style version. }
\begin{tabularx}{\textwidth}{llLLLL}
\toprule
category & \# mod & time (D4) & time (D3) & \# states (D4) & \# states
(D3)\\
\midrule
alg & 9 & 3:52 & 3:51 & 543.3 k & 543.3 k\\
pv264 & 13 & 1:34 & 1:32 & 183.0 k & 183.0 k\\
iv112 & 11 & 25:58 & 25:57 & 3743 k & 3743 k\\
libcxx & 425 & 42:15 & 42:09 & 2182 k & 2182 k\\
bricks & 292 & 3:04:25 & 2:56:55 & 6271 k & 6251 k\\
divine & 3 & 6:20 & 6:18 & 1040 k & 1040 k\\
cryptopals & 3 & 0:01 & 0:01 & 1943 & 1943\\
llvm & 12 & 36:36 & 36:27 & 3865 k & 3865 k\\
svc-pthread & 17 & 16:47 & 16:41 & 1685 k & 1685 k\\
\textbf{total} & 794 & 5:21:44 & 5:13:49 & 20.1 M & 20.0 M\\
\bottomrule
\end{tabularx}
\end{table}

As can be seen in \autoref{tbl:D4D3}, the time penalty on our chosen
model set is very acceptable -- just shy of 2.6\,\% -- and the state
space size is within 1\,\% of the older
approach~\mcite{RBB16}. We believe that this small
penalty is well justified by the superior verification properties of the
new approach.

\subsection{Comparison to Stub
Exceptions}\label{comparison-to-stub-exceptions}

The second alternative approach is to consider any thrown exception an
error, regardless of whether it is caught or not. This can be achieved
much more easily than real support for exceptions, since we can simply
replace the entire \texttt{libunwind} interface with stubs which raise
an error and refuse to continue. This approach only works for models
which do not actually throw any exceptions during their execution. The
results of this comparison are shown in \autoref{tbl:D4stub} -- the
verification time is nearly identical and the state spaces are entirely
so. This is in line with expectations: in those models, catch blocks are
present but never executed. Since the proposed approach does not incur
any overhead until an exception is actually thrown, we would not expect
a substantial time difference.

\begin{table}[tp]
\caption{\label{tbl:D4stub}Comparison of the new exception code against
stubbed exceptions. Compared to \autoref{tbl:D4D3}, in this case 133
models failed due to the stubs and were excluded. State counts are identical for all
models. }
\begin{tabularx}{\textwidth}{llLLL}
\toprule
category & \# mod & time (D4) & time (stub) & \# states\\
\midrule
alg & 9 & 3:52 & 3:52 & 543.3 k\\
pv264 & 13 & 1:34 & 1:34 & 183.0 k\\
iv112 & 11 & 25:58 & 26:00 & 3743 k\\
libcxx & 392 & 41:56 & 41:54 & 2179 k\\
bricks & 192 & 35:30 & 35:21 & 2378 k\\
divine & 3 & 6:20 & 6:19 & 1040 k\\
cryptopals & 3 & 0:01 & 0:01 & 1943\\
llvm & 12 & 36:36 & 36:28 & 3865 k\\
svc-pthread & 17 & 16:47 & 16:43 & 1685 k\\
\textbf{total} & 661 & 2:52:30 & 2:52:08 & 16.2 M\\
\bottomrule
\end{tabularx}
\end{table}

\subsection{Comparison to No
Exceptions}\label{comparison-to-no-exceptions}

Finally, the last alternative is to disable exception support in the C++
frontend entirely. In \texttt{clang}, this is achieved by compiling the
source code with the \texttt{-fno-exceptions} flag. In this case, the
\llvm{} bitcode contains no exception-related artefacts at all, but many
programs fail to build. Additionally, a number of programs in the
``bricks'' category contain exception handlers for memory allocation
errors\mnote{In this case, the handler is installed using
  \texttt{std::set\_terminate}, which is available even when
  \texttt{-fno-exceptions} is given. The situation would be similar if
  only parts of the program were compiled with \texttt{-fno-execptions}.
  In particular, the problem is that the standard library, if compiled
  with \texttt{-fno-exceptions}, cannot throw, and must therefore behave
  differently in those scenarios, affecting the behaviour of the user
  program.} and therefore exit cleanly upon memory exhaustion. Even
though some of those programs can be compiled with
\texttt{-fno-exceptions}, they now contain an error (a null pointer
dereference) which is not present when they are compiled the standard
way. Those programs were therefore excluded from the comparison. The
summary of this comparison can be found in \autoref{tbl:D4nxc} -- the
time saved for models where \texttt{-fno-exceptions} is applicable is
again quite small, less than 13\,\%. In this case, the difference is due
to the changes in control flow of the resulting \llvm{} bitcode. Since
\texttt{call} is not a terminator instruction (does not perform a jump; unlike
\texttt{invoke}),
the \emph{local} control flow in a function is negatively affected by
the presence of \texttt{invoke} instructions: more branching is
required, and this slows down the evaluator in \divm{}. While it is easy to
see if a given program can be compiled with \texttt{-fno-exceptions}, it
is typically much harder to ensure that its behaviour will be unchanged.
For this reason, we do not consider the time penalty in verification of
this type of programs a problem.

\begin{table}[tp]
\caption{\label{tbl:D4nxc}Comparison of the new exception support
against a case where \texttt{-fno-exceptions} was used to compile the
sources and libraries. In this case, it was only possible to verify 423
models from the set (i.e.~371 models are missing from the comparison).
State counts are identical for all models. }
\begin{tabularx}{\textwidth}{llLLL}
\toprule
category & \# mod & time (D4) & time (nxc) & \# states\tabularnewline
\midrule
alg & 1 & 0:24 & 0:23 & 34.2 k\tabularnewline
pv264 & 1 & 0:00 & 0:00 & 57\tabularnewline
iv112 & 10 & 23:58 & 22:06 & 3571 k\tabularnewline
libcxx & 393 & 41:57 & 40:44 & 2180 k\tabularnewline
svc-pthread & 17 & 16:47 & 15:42 & 1685 k\tabularnewline
\textbf{total} & 423 & 1:23:33 & 1:19:21 & 7504 k\tabularnewline
\bottomrule
\end{tabularx}
\end{table}

\subsection{Re-usability}\label{sec:lang:re-usability}

As outlined in \autoref{sec:lang:components}, the two components directly
involved in exception support are comparatively small and well isolated.
The \llvm{} transformation is fully re-usable with any \llvm{}-based tool. The
unwinder, on the other hand, relies on the capabilities of \divm{}.
However, there is no need for hypercalls specific to exception handling
and therefore, the implementation work is essentially transparent to
\divm{}. The capabilities of \divm{} required by the unwinder are limited to
the following: linked-list stack representation, runtime access to the
program frame layout and 2 hypercalls:
\texttt{\_\_vm\_control} and \texttt{\_\_vm\_obj\_free}. More details about
\divm{} can be found in~\mcite{RSCB2018}.

Finally, adding support for a new type of exceptions is also much
simpler in this approach -- no modifications to \divm{} (or any other host
tool) are required: only the two components described in this paper may
need to be modified.

\section{Conclusion}\label{sec:lang:conclusion}

In this work, we have discussed an approach to extending an \llvm{}-based
model checker with C++ exception support. We have found that re-using an
existing implementation of the runtime support library is a viable
approach to obtain complete, standards-compliant exception support. A
precondition of this approach is that the verification tool is flexible
enough to make stack unwinding possible. The \divm{} language, on which the
\divine{} model checker is based, has proven to be a good match for this
approach, due to its simple and explicit stack representation, along
with a suitable set of control flow primitives.

We also performed a survey of tools based on partial or complete
reimplementations of C++ exception support routines and found that in
each tool, at least one edge case is not well supported. In contrast to
this finding, with our approach, all those edge cases are covered ``for
free'', that is, by the virtue of re-using an existing, complete
implementation. Contrary to the prediction made
in~\mcite{RBB16}, we have found that with a suitable
target language, implementing a new unwinder can be relatively simple.
The unwinder implementation described in this paper is only about 210
lines of C++ code, while it would be impossible to implement without
verifier modifications in \divine{}~3. Therefore, we can conclude that with
the advent of the \divm{} specification~\mcite{RSCB2018} and its
implementation in \divine{} 4, re-implementing the \texttt{libunwind} API
and re-using \texttt{libc++abi} became a viable strategy to provide
exception support.
