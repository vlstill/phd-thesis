Historically, automatic analysis techniques for parallel programs started with
analysis of models of systems.
A programmer wishing to use such a tool would either start by creating a model
of the system (in the specification step of the development), and then provide
an executable implementation for this model or, if they already had a working
product, they would have to create a model in order to analyze it.
Such tools include for example SPIN~\cite{Holzmann1997,Holzmann2004}, older version of DIVINE~\cite{BBCS05,BBCR10}, LTSmin~\cite{Kant2015}, \cite{uppall?}, \cite{TODO...}.
Such an approach requires an extra investment in the modelling phase and, even
if analysis of the model concludes it is correct, it does not prove that the
final product is indeed correct.

Later, with the improvement of both analysis techniques, as well as overall
improvement in available computing power, tools which analyse programs written
in mainstream programming languages become available.
Early examples of such tools are Java Path Finder~\cite{Visser2003} (an explicit-state model checker for Java) and CBMC~\cite{Clarke2004} (a SAT-based bounded model checker for C).

Since 2012, the Software Verification Competition (SV-COMP)~\cite{Beyer2020svc} aims
to showcase tools which support direct verification of software written in C
and later also Java.
While it includes mostly sequential programs, there is also a subcategory for
parallel C programs in SV-COMP.

We will now focus in more details on automatic techniques for verification of
parallel programs.
We will not consider program analysis techniques which require substantial manual effort (e.g., proof-theorem-based techniques), or techniques which are not applicable to realistic programs (e.g., techniques which use a special modelling language).
We will also mostly disregard tools with no support for parallel programs.

\section{Explicit-State Model Checking}

Explicit-state model checking is based on exhaustive exploration of the
state-space graph \cite{TODO}.
It checks that a given (finite-state) system satisfies given property.
The property is often given by an LTL formula and the automata-based approach
to LTL verification is used (i.e., the problem is reduced to the problem of
repeated reachability of a state in the state-space graph)~\cite{TODO}.
In the special case of safety properties, it is sufficient to perform graph
search for a state which violates the safety property, for example using the
depth-first search algorithm, or any other graph search.

The advantage of explicit-state model checking is that it is conceptually easy
to apply it to verification of parallel programs (under sequential
consistency), as the interleaving semantics of thread naturally gives rise to
the state space graph.
Furthermore, explicit-state model checking does not require the program to be terminating, it is sufficient that its state space is finite.\mnote{A finite state space can contain cyclical infinite behaviour -- a loop in the state space.

\medskip
\begin{tikzpicture}[>=latex,>=stealth',auto,node distance=2cm,semithick,initial text=]
  \node[state,initial] (t) {$x$};
  \node[state] (f) [right of = t] {$\lnot x$};

  \path[->, shorten >=1pt]
	(t) edge[bend left] (f)
	(f) edge[bend left] (t)
  ;
\end{tikzpicture}
}

In practice, explicit-state model checking is prone to the \emph{state-space
explosion} problem: the number of states in the state-space graph of a
reasonable system can easily be so big it is not possible to store the state
space in the available memory.
Since the algorithm which explores the state-space graph needs to detect which
states were already seen to ensure termination (and to check for LTL
properties), the state space explosion problem can significantly limit
capabilities of explicit-state model checking.

To mitigate state-space explosion, several state-space reduction techniques
were introduced.
Using these techniques, it is possible to explore only some of the states of
the state space in such a way that the property holds for these states if and
only if it holds for the entire state space.
These reduction techniques include \emph{Partial Order Reduction} (POR), which
can eliminate some states by exploring independent events only in one
particular order \cite{Peled1993,Godefroid1996partial,TODO}.
\TODO{...}

Another wide family of reductions are reductions which can coalesce a path in a
state space into a single edge and hide all intermediate states.
This idea was introduced by Lipton in~\cite{Lipton1975}, who introduced the
notion of right movers (``resource acquire operations'') and left movers
(``resource release operations'') to identify statements in program which can
be executed atomically.
However, in analysis of realistic parallel programs a notion of instruction (or
action) visibility is often used -- a group of instructions from one thread can
be executed atomically provided that at most one of them is observable by the
other threads and that this grouping does not influence checking of the
verified property or termination of the search.
Both static and dynamic reduction methods were proposed, under many names,
including D-reduction~\cite{Lipton1975}, path reduction~\cite{Yorav2004}, $\tau$ reduction~\cite{BBR2012}, \TODO{…} for the static variants and $\tau+$ reduction~\cite{RBB13} and \cite[Section 6]{RSCB2018}, \TODO{...} for the dynamic once.
The reductions are also often used without naming the technique, for example in
Java Path Finder~\cite{Visser2003}.
Quite naturally, the dynamic methods are better suited for the complex control-
and data-flow of realistic programs.

Partial order reductions and path reductions are often also used in tools based
on other principles then explicit-state exploration.

Additionally, there are variants of \emph{symmetry reductions} which reduce the
state space by coalescing states which differ only in properties not relevant
for the program analysis.
For example the \emph{heap-symmetry} reduction allows to consider two states
that differ only in the order in which memory objects were allocated to be the
same~\cite{RBB13}, \cite[Chapter 6]{RSCB2018}, \cite{TODO}.
A dead-variable reduction~\cite{Yorav2004,Yorav2004:4,TODO} can be also seen as an instance of symmetry reductions.
\TODO{...}

These state space reduction techniques can reduce the number of states by
several orders of magnitude~\cite{TODO}, and therefore enable verification of
realistic (but still relatively small) programs.

Interestingly, the proposed reduction techniques which aim to preserve verified properties are not always correct, for example the original version of $\tau+$ reduction considered only stores to be visible, but it was later shown that repeated loads have to be also visible (shown by me in~\cite{S2016}, acknowledged an fixed in \cite[Section 6]{RSCB2018}).\mnote{%
\cpp{int x = 0;}\\
\cpp{void t0()} \texttt{\{}\\
\cpp{  x = 1;}\\
\texttt{\}}\\
\cpp{void t1()} \texttt{\{}\\
\cpp{  int a = x;}\\
\cpp{  assert(a == x);}\\
\texttt{\}}

The assertion is violated if \cpp{t0} executes between the (local, invisible)
assignment and the assertion in \cpp{t1}.
However, if repeated loads are not considered visible, they are coalesced and
the assertion is not violated.
}
Similar problem was present in \cite{Cordeiro2011} where ESBMC could perform two conditional jumps which read the same shared variable with no context switch between them (section 3.1, rule R3).
Interestingly, the authors notice the possibility of missing context switches, but only introduce an option to fix it, leaving the problematic behaviour as default.

To further improve capabilities of explicit-state model checking, several
techniques for compact representation of the set of visited states were
introduced.
These techniques include \emph{hash compaction} and \emph{bitstate
hashing}~\cite{Holzmann1998}, which are incomplete techniques which use hashes
of states instead of storing the entries states (and therefore can omit some
parts of the state space if there is hash collision),
\emph{probabilistic storage of states}\TODO{...}, and
\emph{lossless compression techniques}~\cite{RSB15TC,Laarman2019} which aim to design compact but representation of the state space which can still facilitate fast lookups.

\paragraph{Data Nondeterminism}
While explicit-state model checking can easily represent control-flow
nondeterminism, it is not well suited for data nondeterminism, as it is not
practical (or even possible) to explicitly enumerate all possible values of
data domains.
Therefore, if data nondeterminism is required, explicit-state model checking
needs to be combined with some technique for symbolic of abstract data
representation.

\paragraph{Tools}

The pioneering tool is the SPIN LTL model
checker~\cite{Holzmann1997,Holzmann2004}, however, it has a very limited
support for analysis of realistic programs.
SPIN targets a parallel modelling language PROMELA, which has support to embed
C code to define atomic an atomic step.
In~\cite{Zaks2008} SPIN was extended to have partial support of C with the need
to define a test driver in PROMELA.

Java Pathfinder (JPF)~\cite{Artho2019,Visser2003} is an explicit state model
checker (with later symbolic extensions) for Java and JVM-based\mnote{Java is
not executing directly on the target hardware but instead uses an intermediate
language which is executed by JVM. Other languages (e.g., Scala, Kotlin) can
also target JVM and share the intermediate representation with Java.}
languages.
From its beginning JPF targets concurrent Java programs.
It checks for safety properties, namely for uncaught exceptions which in Java also subsume assertion checking and bound checking.
To reduce state space JPF uses hash-compaction (and therefore under-approximates all possible behaviours) and groups instructions with local effects.
Interestingly, the instruction grouping in JPF uses a heuristic which can cause it to miss some behaviours.
JPF has also model of parts of the Java standard library (including limited IO
support) and limited support for execution of native code from the Java
code\mnote{Java programs can use the Java Native Interface (JNI) to interfere
with native code, for example in order to access operating system primitives
directly.}
In addition to scheduling nondeterminism, JPF can use explicit choice as an
additional source of nondeterminism.
The symbolic extension, Symbolic Pathfinder (SPF)~\cite{Pasareanu2013,Noller2019} adds
support for symbolic data representation using symbolic execution.
It supports test generation and detection of assertions and concurrency errors.
It primarily targets unit tests and sub-system level testing and has a
possibility to use unit preconditions and combine symbolic and explicit
execution.
To explore different possible interleavings, SPF uses the explicit JPF without
state comparison and with depth bound to ensure termination (the state
comparison can be enabled but then disregards the symbolic data and therefore
can miss many behaviours).
Interestingly, SPF is able to handle certain cases of dynamically allocated
linked symbolic data by \emph{lazy initialization} -- when a symbolic pointer
is accessed it can be expanded to either null pointer or another node of
symbolic data \cite{Khurshid2003}.
SPF has support for symbolic arrays~\cite{Fromherz2017} and symbolic strings~\cite{Bang2016}.

DIVINE~\cite{DIVINEToolPaper2017} is an explicit-state model checker developed
by our research group.
Historically it targeted several modelling languages for parallel systems and
LTL verification using parallel and distributed algorithms, but later it
shifter towards analysis of C and C++ using the LLVM intermediate language.
While it now aims primarily at verification of safety properties (assertion
violations, memory access safety, detection of use of undefined variables,
detection of memory leads, numeric manipulation errors, deadlock-freedom for
the POSIX mutexes, …) it has also limited support for LTL and there is also an
extension for detection of nontermination in concurrent programs
(\autoref{chap:lnterm}, \cite{SB2019}).
To tackle realistic programs, DIVINE uses a dynamic detection of invisible
actions ($\tau+$ reduction) and an efficient representation of program memory
which facilitates heap-symmetry reduction and state-space
compression~\cite{RSCB2018}.
DIVINE has also support for symbolic and abstract data representation using
program transformations \cite{LRB2018}.
Currently it supports symbolic bitvector manipulations for integers and floats
and symbolic string representation~\cite{CLR2019}.
With the symbolic data representation using bitvectors, DIVINE uses SMT solvers
to check for feasibility of traces and to compare symbolic states -- this way
it retains the ability to join states which are semantically equivalent even if
the symbolic data are represented by a different formula and therefore DIVINE
with symbolic data can use LTL properties.
One of the main goals of DIVINE is to support verification of C and C++
programs which use existing libraries.
To this end, DIVINE has almost complete standard C and C++ libraries (as of
C++17), the POSIX thread library (\texttt{pthreads}), and it also supports C++
exceptions (\autoref{chap:lang}, \cite{SRB2017}).
To reflect behaviour of concurrent programs on contemporary hardware, DIVINE
has also support to analyse programs with respect to the \xtso memory
model~(\autoref{chap:mm}, \cite{SB2018x86tso}).
DIVINE has also an in-built compiler based on LLVM's clang and support for significant parts of POSIX filesystem and process APIs~\cite{RBMKB2019}.

Another explicit-state model checker from our research group is
\textsf{SymDIVINE}~\cite{MBLB2016} which combines explicit control flow
handling with symbolic representation of data using bitvectors (with symbolic
state equality).
\textsf{SymDIVINE} targets safety and LTL properties in C programs.
This tool is now discontinued in favor of aforementioned symbolic data support
in DIVINE.


% LTSmin~\cite{Kant2015}
% - probabilistic, timed systems
% - multi-core LTL model checker, partial order reduction
% - multi-core symbolic checking for $\mu$-calculus
% - multiple modelling formalism, but no realistic programming languages
% - state space compression
% - paralell LTL search

\section{Stateless Model Checking}

\TODO{(= Systematic concurrency testing)}

Compared to explicit-state model checking, stateless model checking (SMC)
avoids storing the set of visited states and therefore has decreased memory
consumption.
Furthermore, since the state representation is not required to be as compact as
possible, stateless model checker can have simpler representation of states.
Stateless model checking was introduced in~\cite{Godefroid1997}, it aims at
safety analysis of terminating realistic parallel programs.
A stateless model checker usually explores the state space in depth-first
manner and it can explore some parts of the state space multiple times (since
it does not store the set of visited states).
Therefore, the requirement that input program is terminating is necessary to
ensure the verification procedure terminates.
In practice, this requirement is often ensured by imposing loop iteration
bounds -- loops are assigned maximum allowed number of iterations, if the
program under test requires more iterations of some loop, the loop bound can be
increased, or the analysis can be terminated as inconclusive.

Without additional state space reductions, SMC would lead to redundant
explorations of many parts of the state space -- in parallel programs it is
common that two or more actions of different threads are independent and
regardless of their order they lead to the same end state.
In this case a stateless model checker would explore a state as many times as
is the number of paths from the initial state to this state (in the worst case
the number of paths to a given state can be exponential to its distance from
the initial state).
To mitigate this problem, dynamic partial order reduction
(DPOR)~\cite{Flanagan2005dpor} is often employed with SMC.
DPOR is a version of partial order reduction that tightly integrates with
the SMC exploration algorithm and keeps track of parts of the state space which
still need to be explored.
Using DPOR, SMC can avoid redundant exploration of equivalent paths in the
state space.

Many works are concerned with design of efficient DPOR methods both for
parallel programs running under sequential consistency (interleaving
semantics), and for various memory models.
This is usually accomplished by combination of two aspects: an equivalence of
traces and an exploration algorithm which ensures at least one trace (and in
optimal case exactly one trace) from each equivalence class is explored.
The trace equivalence has to be designed in such a way that for each of its
classes either all traces contain only safe states or all traces contain an
unsafe state -- i.e., the equivalence preserves safety properties.

For sequential consistency, multiple DPOR techniques were introduced.
\TODO{Verisoft, CHESS, techniky} \cite{TODO,TODO}, among these \cite{Abdulla2014} is interesting by providing an optimal algorithm for equivalence based on \emph{Mazurkiewicz traces}~\cite{Mazurkiewicz1987} (where traces are considered equivalent if one of them can be obtained from the other by swapping adjacent non-conflicting execution steps).
While the original implementation of the is technique was used for verification of Erlang programs (which use message passing instead of shared variables) using the Concuerror tool, it was later successfully applied also to verification of C programs under TSO and PSO memory models using the Niddhugg SMC \cite{Abdulla2017tso}.

It is important to note that the optimal DPOR presented by \cite{Abdulla2014}
is optimal for the given trace equivalence.
A data-centric DPOR which uses a coarser equivalence and an optimal
exploration algorithm for it was introduced in~\cite{Chalupa2017} and it was
shown that it performs better on a selection of C benchmarks.

Another approach based on observation of read and written values is Maximal
Causality Reduction (MCR)~\cite{Huang2015}, which can be seen as an alternative
to DPOR.
\TODO{MCR employs an SMT solver to find new traces to explore which allows it to
explore less interleavings then Mazurkiewicz-trace-based DPOR techniques.}
Another advantage of MCR is that it can be easily modified for parallel
exploration (DPOR cannot be easily executed in parallel).

\TODO{...?}

\paragraph{Relaxed Memory Models}

\TODO{rewrite?}

Thanks to its ability to reduce exploration of redundant interleavings, SMC
combined with DPOR or other reduction techniques is often used as a basis for
analysis of programs running under various relaxed memory models.

Several approaches focus on the TSO/\xtso memory models (and often also on PSO,
which is somewhat more relaxed then TSO, but can usually be simulated in a
similar manner).
These include \emph{rInspect} presented in~\cite{Zhang2015}, which uses store
buffers and shadow threads which flush them to integrate relaxed memory with
existing DPOR approaches for sequential consistendy.
The tool \emph{rInspect} is based on LLVM and targets primarily C programs.
It has support for both bounded and unbounded store buffers (but being a SMC it
works on terminating programs only).
Another approach to TSO and PSO is used by tool Niddhugg and presented
in~\cite{Abdulla2017}.
This approach uses \emph{chronological traces} that capture dependencies between
memory operations.
Chronological traces are then used with the optimal DPOR
from~\cite{Abdulla2014}, which gives rise to an interesting property -- for
robust programs (i.e., programs which do not exhibit observable relaxed
behaviour) the number of traces explored under TSO or PSO should be the same as
the number of traces explored under sequential consistency.
Niddhugg is an LLVM-based tool for analysis of C programs.
A SAT-based stateless approach is presented in~\cite{Demsky2015}.
It targets both sequential consistency and \xtso and is implemented in the tool
SATCheck.
It repeatedly executes a concrete interleaving of threads (and records
dependencies in this execution) and invokes SAT solver to find new
interleavings with different behaviour.

For the C11/C++11 memory model~\cite{Norris2013} presents a tool \textsc{CDSChecker}.
It covers most of the C11 memory model, with the exception of release-consume
synchronization and executions which exhibit out-of-thin-air
values.\mnote{Out-of-thin-air values \TODO{...}.}
To allow reads which are reordered with future operations (which is allowed by
the C11 memory model), \textsc{CDSChecker} can propagate stored values to
previous loads and validate this speculation.
\textsc{CDSChecker} targets primarily unit tests of concurrent data structures
written in C11/C++11.
A different approach to stateless model checking of programs running under the
C11/C++11 memory model is taken in~\cite{Kokologiannakis2017}.
This approach uses the RC11 memory model, which is a proposed memory model
which fixes some of the problems with the C11/C++11 memory
model~\cite{Lahav2017}.
Here, the authors use execution graphs which represent visible program actions
and dependencies between them to explore all behaviour of a given program.
This allows them to cover all program's behaviour without direct exploration of
its interleavings.
The approach is implemented in the tool RCMC.


In~\cite{Abdulla2016} an approach for stateless model checking under the POWER memory model is show.
The work presents a way to derive a suitable execution model from the axiomatic semantics of the memory model, and an SMC exploration algorithm for the execution model.
The proposed approach explores only a single complete trace from each equivalence class given by Shasha-Snir traces~\cite{Shasha1988}, but it can perform redundant exploration of incomplete traces. 
The algorithm is implemented in the tool Nidhugg.


---

CHESS:
- state hashing (according to \cite{Cordeiro2011})


SATABS (unknown type)
- according to \cite{Cordeiro2011} cannot handle arrays + arithmetic

Nidhugg~\cite{Abdulla2017}



\paragraph{Limitations of SMC}

As already mentioned, the SMC requires programs to be terminating, which is
usually achieved by bounding loops and recursion.
For this reason, SMC is limited only to properties of finite paths, and
therefore it cannot be used for general LTL properties or showing program
nontermination.

Furthermore, most SMC techniques require programs to have no source of
nondeterminism apart from thread scheduling and memory model (i.e., no data
nondeterminism)~\cite{Abdulla2017}.
\TODO{ deteministic threads: \cite{Huang2015:14,Huang2015:27}}


\section{Bounded Model Checking \& Related Techniques}

Bounded model checking (BMC) was introduced in~\cite{Biere1999} as an alternative to
symbolic model checking techniques which used binary decision diagrams.
BMC encodes program runs of fixed length into propositional formulas, or
formulas over some first-order logic.
Then in relies on SAT or SMT solvers to decide if the formula is satisfiable or
not.
One of the advantages of BMC is that is naturally handles data nondeterminism.

The original paper introducing BNC presented a verification procedure for LTL
(which detected loops in the program runs by checking equality of the last
state of the bounded run to some of its previous states).
However, for realistic programs the focus is mainly on safety properties, and
more recently also on (non)termination.\mnote{For tools which use approximation
or heuristics, checking for termination is not the same as checking for
nontermination as the tool might simply return \emph{unknown} result if it
fails to prove its objective (i.e., termination or nontermination).}

\TODO{Most BMC tools build formula from SSA form of the program… 
+ bound on the number of times each loop might be executed (unwinding),
bounded recursion depth
… Rabinovitz2005}

We have identified three broad approaches to support of concurrent programs in
BMC.
The conceptually simplest is to explicitly enumerate symbolic context-switch
bounded runs of the program and then encode them to resolve symbolic data.
This is the approach used by ESBMC~\cite{Cordeiro2011} and by
\cite{Rabinovitz2005} for an early concurrent extension of CBMC.
Another approach is to encode control flow of threads separately and add scheduling constraints which specify inter-thread ordering.
This approach is used by CBMC~\cite{Alglave2013po} and also proposed in~\cite{Ganai2008}.
The last approach is sequentialization, which makes use of a BMC for sequential programs and a pre-processing step which converts a parallel program into a nondeterministic sequential program.
Many sequentialization schemes were proposed, differing both in the size of the encoding and the way they limit thread interaction (e.g., limit to the number of context switches, to the number of shared-variable interactions, …)~\cite{Qadeer2004?,TODO...}.

The main limitation of BMC is that it explores only runs up to some length
bound $k$.
Therefore, BMC alone cannot prove correctness unless it shows that the loop
bound was sufficient (for example by inserting a special \emph{unwinding
assertions} into the program and showing they are not violated).
To mitigate this limitations BMC can be combined with other techniques which
aim to prove correctness of the program, such as $k$-induction~\cite{TODO} or
IC3~\cite{TODO}.

\paragraph{$k$-Induction}

$k$-induction~\cite{Donaldson2011,Gadelha2017} is an extension of
bounded model checking which allows it to find bugs faster and to prove
correctness of programs without unwinding loops fully.
Multiple $k$-inductions schemes exists, in the one proposed in~\cite{Gadelha2017} a verifier with $k$-induction repeatedly performs three steps with an increasing bound $k$.
\begin{description}
    \item[Base Case] checks if an error is reachable in $k$ steps.
    \item[Forward Condition] checks if all program's paths had terminated in
        $k$ steps (i.e., the verification is done as the tool had already
        explored all states).
    \item[Inductive Step] checks that if the property holds for the first $k$
        steps, it also holds for the $k+1$ steps.
        This is checked in a modified program in which all loop variables are
        initialized to nondeterministic values before the loops and the loops
        are required to execute to completion.\mnote{This can be achieved by
        instrumenting \texttt{assume} statements which ensure that the loop
        body is entered and that after the given number of iterations the
        condition for loop termination holds.}
\end{description}
\TODO{Nested loops are unwound recursively}
One of the problems with $k$-induction is that the induction argument is not strong enough to prove the inductive step.
For this reason, the induction can be strengthen by invariants derived from the original program (i.e., the nondeterministic values of loop variables are constrained by the invariants).

\paragraph{IC3} \TODO{TODO}


\paragraph{Tools}

The original bounded model checker BMC~\cite{Biere1999} was an LTL bounded
model checker which targeted a modelling language.


CBMC~\cite{Clarke2004,Kroening2014} is a widely used SAT-based bounded
model checker for sequential and parallel C programs.
It uses bit-precise encoding and therefore preserves semantics of computer
integers.
CBMC can detect safety errors, it uses instrumentation for detection of errors
other then assertions.
For efficient analysis of parallel programs CBMC uses encoding based on partial
orders described in~\cite{Alglave2013po} -- it builds the formula from the SSA
form of each thread and ordering constraints for shared variables.
CBMC is notable for its support of relaxed memory models, including \xtso,
POWER memory model and sequential consistency~\cite{Alglave2013po}, \TODO{cite
more…}.

\TODO{
CBMC \cite{Kroening2014,Clarke2004}
- parallelism, weak (SC, x86, POWER), uses partial orders  for efficient encoding of parallelism \cite{Alglave2013po} instead of interleavings (\TODO{? :30, :36, :6})
- relaxed memory has little impact on performance
- SC: \cite{Alglave2013po:25}
- k-induction?? (\cite{Gadelha2018:7})
}

ESBMC~\cite{Gadelha2018,Gadelha2019}, is another widely used BMC for C
programs in which it can detect assertion violations, memory errors, overflows and \TODO{mutex-caused} deadlocks.
ESBMC was derived from CBMC, it uses SMT for encoding of the program and has
support for $k$-induction with invariant generation (based on interval analysis
of integral variables; the invariant generation is currently unsound for
programs with pointers).
The support for concurrency in ESBMC is described in~\cite{Cordeiro2011}.
Interestingly, ESBMC explores possible program interleavings explicitly and
doing so it collects constrains on nondeterministic variables, which are then
used to generate a formula.
The formula can be generated and solved either for each run separately (lazy
approach), which has the advantage of being incremental, or all interleavings
can be encoded into one formula (schedule recording) which uses guards to
encode scheduling of each interleaving.
There is also encoding based on under-approximation and widening which attempts
to produce more compact encoding.
The approximation uses proofs of unsatisfiability of the formula for refinement.
The lazy approach seems to work best according to~\cite{Cordeiro2011}.
Regardless of the formula encoding, ESBMC uses bound on the number of context
switches.
In order to limit number of runs which need to be explored, ESBMC allows
context switches only at visible instructions (i.e., instructions which access
shared memory).
The handling of parallelism in ESBMC makes it closely related to explicit-state
model checkers with symbolic extensions, like Symbolic Pathfinder or DIVINE.
Similarly to CBMC, ESBMC used a custom C parser, but it had later switched to
using the clang compiler for parsing C and C++.
Unlike other tools which use clang, it does not use the LLVM intermediate
representation, but instead builds its own internal representation based on the
C/C++ AST produced by clang.

ESBMC has also derivatives which aim at C++ verification.
ESBMC++~\cite{Ramalho2013} uses a model of parts of the standard C++ library,
has support for C++ exceptions and inheritance.
$\text{ESBMC}^{\textit{Qt}OM}$~\cite{Sousa2015,Garcia2016} adds a model
of parts of the Qt framework for C++ programs.
In both cases the models approximate behaviour of the respective libraries
based on the standard or documentation.

JBMC~\cite{Cordeiro2019,Cordeiro2018}, is a bounded model checker for
Java built on the same basis as CBMC.
It uses combination of SAT and SMT solving with a dedicated solver for string
operations.
JBMC has support for exceptions (by lowering them to jumps in its intermediate
representation) and has an exact verification-friendly model of most common
parts of the Java standard libraries.
It can detect assertions, memory errors, integral overflows an type casting
errors.
JBMC has no support for threads currently \TODO{oveřit s SVC 2020}.
It also lacks support for the Java Native Interface (JNI) and reflection.

LLBMC~\cite{Merz2012,Falke2013} is an SMT-based bit-precise BMC for
sequential C and C++ programs which is notable for its used of the LLVM
intermediate representation which allows it to reuse existing C and C++
compilers.
It is also one of the few tools which have support of C++, although with some
limitations, most notably there is not support for exceptions and run-time type
support and there is no support for threads and floating-point arithmetic for
both C and C++.
It can detect assertion violations, integer overflows, invalid shifts, memory
errors and memory leaks.
\TODO{unmaintained}

Another LLVM-base tool is LLVMVF~\cite{Sousa2013} which is a generic verification framework on which a BMC for parallel programs is built.
Concurrency support in LLVMVF is incomplete, for example it lacks support for condition variables.
\TODO{unmaintained}

Yogar-CBMC~\cite{Yin2018,Yin2019} is a derivative of CBMC which uses
abstraction and refinement for the encoding of scheduling constraints in
parallel programs in order to make the formulas smaller.
Unlike CBMC, it has no support for relaxed memory.
It can run multiple counterexample-guided refinement loops in parallel and they
share the learned scheduling constraints in order to analyze the program
faster.
Yogar-CBMC was able to solve all concurrency benchmarks in SV-COMP 2019 and significantly outperformed CBMC.

CBMC-Path~\cite{Khazem2019} is another derivative of CBMC, it encodes paths in
the state space one by one instead of building a formula for the whole
(bounded) state space of a parallel program.
While it was designed to facilitate faster bug discovery for SV-COMP it performed significantly worse than CBMC.

DepthK~\cite{Rocha2017,Rocha2017svc}, is a tool based on ESBMC with
addition of polyhedral invariants which aim to strengthen inductive step in the
$k$-induction.
It was presented before ESBMC gained ability to compute invariants itself and it uses an external tool for invariant generation.
DepthK can analyze concurrent C programs.

\TODO{\textsc{Dartagnan}~\cite{PonceDeLeon2020,Gavrilenko2019}}
- BMC for relaxed memory models, relaxed memory model can be specified on input, not encoded in the verifier
- for C, internally uses \textsc{Boogie} intermediate language (translates using SMACK)
- uses symbolic encoding which encodes relations such as program order, data dependencies, read-from -- memory model specification constraints them
- safety properties
- does not support pointer arithmetic
- should support wide range of memory models including \xtso, ARMv8, POWER, C/C++11 + Linux kernel memory model including primitives such as RCU\mnote{Read-copy-update \TODO{…}}.
- relation analysis to reduce size of the encoding -- determines which pairs of events may influence constraints specified by the memory model

Lazy-CSeq~\cite{Inverso2015,Nguyen2017} is a sequentialization-based
tool for analysis of concurrent C programs which uses bounded model checker as
a backend (CBMC by default).
It performs source-to-source transformation from a concurrent C program to a
sequential C program which simulates a bounded number of round-robin scheduling
rounds (i.e., the number of context switches is limited and the threads are
required to execute in a fixed order, with possibility to perform no steps in a
given round).
This way Lazy-CSeq can simulate a bounded number of interleavings with small
memory overhead and limiting additional nondeterminism compared to the
additional program.
It can detect errors detectable by the used backend, plus POSIX mutex
deadlocks.
In order to speed verification, Lazy-CSeq uses Frama-C~\cite{Canet2009} to
infer  bounds of integral variables and shrink the corresponding bitvector
formulas.
\TODO{\cite{Inverso2020}
- parallelization by partitioning the set of execution traces into independent instances
-
}

\TODO{- the formula size if O(|orig prog.| * |n threads| * |n rounds|)
- Lazy = explores only reachable state space (compared to Akash Lal \& Thomas Reps: Reducing concurrent analysis under a context bound to sequential analysis), does not start after each context switch from nondeterministic values}

MU-CSeq~\cite{Tomasco2015,Tomasco2016} and IMU-CSeq~\cite{Tomasco2017}
are sequentialization-based tools for analysis of concurrent C programs which
uses CBMC as a backend.
They work by nondeterministically guessing a bounded sequence of shared memory
writes and then simulating the program so that its runs match this sequence.
Optionally it can allow also unobserved memory writes which are not part of the
sequence to execute.
The difference between the tools is that IMU-CSeq uses a separate sequence for
each memory location, while MU-CSeq has a single sequence of visible memory
operations.
IMU-CSeq has also support for relaxed memory (TSO, PSO) by the means of
\emph{Shared Memory Abstraction} which defines behaviour of memory operations
and synchronization primitives of the given memory model.

\TODO{- eager = threads are executed separately, with nondeterministic values for shared memory reads, runs are pruned}


---

BLITZ~\cite{Cho2013}
- decomposes the verification instance using approximations of preconditions of property violation which are gradually refined
- the proofs of unsatisfiability (for the under-approximated instance) provide information used for the refinement
- aimed to larger programs (100kloc)
- C programs, including assertions and memory safety
- no mention of paralelism

TCBMC~\cite{Rabinovitz2005}
- context-switch bounded
- extension of CBMC to concurrent programs
- adds support for race and deadlock detection
- only two threads and no deadlocks detection in the implementation

CheckFence~\cite{Burckhardt2007}
- a tool for checking implementations of concurrent data structures in C against a memory model
- Uses a test program as a specification -- it checks if the set of all executions under the given memory model is a subset of a set of \emph{serial executions} which are sequentially consistent executions in which each operation with the data structure is atomic.
- encodes threads and scheduling separately


NBIS~\cite{Gunther2016}
- incremental BMC - can change bounds without throwing away the formula
- uses incremental solvers
- LLVM IR based, for C sequential programs
- not maintained

F-Soft~\cite{Ivancic2005}
- for sequential C programs, safety
- uses BMC (and BDD-based model checking)
- program slicing, predicate abstraction
- generates executable counterexamles


Corral

\paragraph{Limitations of BMC}

- bounded depth
- functions inlined (… function pointers)/recursion bound

\section{K-Induction, IC3, …}

\paragraph{$k$-Induction}


\cite{Donaldson2011}: \textsc{K-Inductor}, \textsc{K-Boogie}
<- CBMC based
-> extension of Boogie
- \TODO{...}

\section{TODO: Misc}

VVT~\cite{Gunther2016}
- CTIGAR = SMT-based IC3 with CEGAR (Counterexample-Guided Abstraction Refinement \TODO{\cite{Birgmeier2014,Bradley2011}}
- parallel C programs
- can analyze infinite-state systems (with finite number of threads, arrays with statically known bounds)
- no unwinding of transition relation
- uses LLVM IR, clang for translation on C
- blocks of instructions which can be executed atomically are identified, context-switch points are instrumented into code
- uses linear arithmetic (to allow interpolation)
- uses a BMC for fast counterexample detection
- not maintained

VIAP~\cite{Rajkhowa2019,Rajkhowa2017}
- aims at programs with loops, does not need invariants
- C programs without dynamic memory, floats, concurrency
- uses integral arithmetic
- translates to quantified first-order formulas over integers
- non-bounded loops
- can use preconditions and postconditions, or assertions

\textsc{Ultimate Automizer}~\cite{Heizmann2017,Heizmann2013}
- C programs, including concurrency
- CEGAR
- automata-theoretic verification approach
- assertion reachability, memory safety, absence of integral overflows, termination
- converts programs to automata (starting with automaton derived from control-flow graph), checks reachability of error states by checking feasibility of error traces
  - the abstraction is refined by counterexample to error trace feasibility
  - refinement by construction of automaton of spurious traces -- Floyd-Hoare automaton (constructed on-demand)
  - uses SMT solver in the refinement
- uses nested words automata for interprocedural analysis~\cite{TODO}
- (non)termination checking~\cite{TODO: Buchy automizer} uses ranking functions and nontermination arguments

\textsc{Ultimate Taipan}~\cite{Dietsch2020,Greitschus2017}
- combines the approach of UA with analysis of \emph{path programs} (projects the original program into an error trace to obtain a corresponding path program which can contain loops (and only contains statements found on the trace)
- attempts to show trace infeasibility by proving unreachability of the error location in the path program using invariants
- newer version uses SMT formulas to represent program states

\textsc{Ultimate Kojak}~\cite{Nutz2015} is another related tool which uses a different algorithm for the refinement step.

Skink~\cite{Cassez2017}
- C programs, supports concurrency
- uses LLVM IR
- uses refinement of trace abstraction algotithm \TODO{(like UAutomizer), cite}
  - uses automata refinement, starting from control-flow automata
  - SMT used to check feasibility of traces
  - for concurrency uses product of thread automata
    - uses POR (based on source-DPOR by \cite{Abdulla2014})
- requires full inlining (no function calls)
- uses integer arithmetic, not bit-precise
- assertion reachability

JayHorn~\cite{Kahsai2019}
-- encoding to horn-clauses, not conucerrency, not bitprecise, basic library (mostly assumes library calls return arbitrary values- can handle certain cases of unbounded heap data structures by deriving invariants, nonterminating programs

CPAchecker~\cite{Dangl2015,Beyer2011}
- C
- a tool and a modular framework which aims at easy integration of new components
- multiple abstract domains can be combined together
- intended as a platform for research of new verification ideas
- k-induction, predicate analysis, …
- bit-precise validation of counterexamples
- memory graphs for memory safety as of~\cite{Dangl2015} (but later in SV-COMP yes)
- reachability, memory safety
- multiple derived tools in SV-COMP
  - CPA-BAM-BnB~\cite{Andrianov2017}
    - BAM = Block Abstraction Memoization: divides program into blocks and analyzes them separately (block = function), cache to reuse block abstractions, uses value analysis and predicate analysis + refinement on spuroious conterexamples
    - BnB -- modelling of memory using predicate analysis, uses uninterpreted functions to map memory locations to memory values, memory is split into regions, each region has its own mapping function.
  - CPALockator~\cite{Andrianov2018}
    - for concurrency, detects race conditions
    - aims to be lightweight at the cost of missed errors
    - tracks locks, which thread are active at given time
    - predicate analysis, CEGAR to exclude spurious race conditions
  - CPA-Seq

SMACK~\cite{Rakamaric2014,Carter2016,Garzella2020}
- translates LLVM IR into Boogie intermediate verification language
- uses Boogie and Corral (default) as backends, intended to allow easy prototyping of backend verifiers
- can use bitvectors or arbitrary-precision ingegers
- boogie does not have dynamic memory -> memory is partitioned into disjoint regions which are represented by maps in boogie
- bug-finder for C and Rust
  - only basic library support (allocation, C string and math operations, pthreads, models of most common Rust libraries)
- \cite{Garzella2020} provides a large study of adding support for C++, Objective-C, D, Fortran, Swift, and Kotlin to SMACK
  - they state models of standard libraries need to be written manually (i.e. reusal not considered)
  - heavy reliance on LLVM for basic support
  - shows limits of SMACK's handling of LLVM
  - only limited support for runtime and libraries (especially in runtime-heavy languages like Swift, Objective-C and Kotlin)
    - pratialy reuse of existing library (Kotlin arithmetics)
    - partly rudimentary models
  - cross-language verification (mostly for free due to LLVM)
- with concurrency-enabled backend (e.g. Corral) supports concurrency

GACAL
- generates potential invariants from traces and verifies them using the ACL2 theorem prover
- only a subset of C (no arrays, only 32 bit integers, …)

Predator/PredatorHP~\cite{Peringer2020,Dudka2013}
- shape analysis of sequential C -- targets memory errors, assertions -> can handle unbounded lists
  - targets programs which use lists (singly/doubly-linked, circular, nested)
  - uses symbolic representation of the memory (symbolic memory graphs)
- only limited handling of non-list types
- uses function summaries, recursion depth bound
- uses GCC compiler
- PredatorHP is an extension which runs several configurations of Predator in parallel (a verifier which can prove correctness but overapproximates and several bug hunters which can show incorrectness)

VeriAbs~\cite{Afzal2019}
- portfolio verifier -- uses different independent techniques for program analysis
- targets sequential C programs with loops
- lightweight analysis to infer which technique should be used, based on the type of loops and data used in them
- techniques include: random fuzz testing, array abstractions, explicit-state model checking, loop invariant generation, CEGAR, loop abstraction, loop summarization, BMC, k-induction

\textsc{PeSCo}~\cite{Richter2019,Czech2017}
- tries to predict order of configurations of a verifier to run on a given task using machine learning
- uses 6 configurations of CPAchecker as a basis
- learning uses graph encoding of programs

VeriFuzz~\cite{Basak2019}
- fuzz testing with lightweight analaysis and instrumentation to extract useful infromation about the program
- coverage driven
- uses evolutionary algorithm to generate test inputs and learning algorithm based on decision trees to decide which techniques to use for fuzzing
- uses loop unrolling (with increasing bounds)

\section{Symbolic Execution}

Introduced in~\cite{King1976}.

Concolic execution = dynamic symbolic execution: programs runs with concrete values but tracks symbolic constraints on branches which are used to generate new concrete values to explore different paths


Symbiotic~\cite{Chalupa2018,Chalupa2020}
- for sequential C programs
- assertions, memory safety, memory leaks, integral overflows
- uses instrumentation to add checks where needed (pointer analysis to limit number of inserted checks)
  - pointer analysis has to account for deallocation
- slicing to remove code irrelevant for the property 
- uses Klee symbolic executor as a backend
- integrates shape analysis based on Predator\cite{TODO} for memory safety checking
- basic non/termination
    - can detect simple cycles in the program state space and therefore in some cases decide the program does not terminate (non-nested loops which preserve values of all variables)
    - can conclude the program is termingating if all paths were explored
- sequential programs

Pinaka~\cite{Chaudhary2019}
- C
- uses incremental solver to check path feasibility (either fully incremental -- reuses one solver instance for the whole program, which can cause big formulas, or partially incremental -- creates new instance on backtracking)
- may not terminate on nonterminating programs, option for unwinding limit
- can be used to show termination -- if program is found to be safe without any unwinding limit, then all its paths terminate

\textsc{JDart}~\cite{Mues2020,Luckow2016}
- java, assertion checking, uncaught exceptions
- concolic execution, test generation
- attempts to find small values for symbolic variables (can make loops depending on symbolic values shorter)
- built on JPF
- no concurrency

Java Ranger~\cite{Sharma2020}
- symbolic execution with path merging by summarization of regions with multiple paths (e.g., branches of an \texttt{if} statement) (\TODO{veritesting})
- extension of SPF

COASTAL~\cite{Visser2020}
- concolic execution + fuzz testing for Java
- uses instrumentation
- can explore different parts of the symbolic execution tree in parallel (with different fuzzer or concolic executor instances)
- fuzz testing can be used for fast exploration, it tracks only direction of branches
- in combilation uses fuzz testing to explore easily-accessible parts of state space and concolic execution to get to the harder
- uses models for some Java classses, but seems to be able to handle original java bitecode libraries (?)
- no symbolic arrays

Map2Check~\cite{Rocha2020}
- fuzzing, symbolic execution, inductive invariants for safety checking C programs
- uses LLVM, Klee
- no concurrency
- fuzzing used to find shallow bugs, symbolic execution for deep
- can use multiple fuzzers in parallel

Map2Check~\cite{Rocha2015} (previous version)
- memory safety + memory safety unit test generation for C using ESBMC
  - including memory leaks, invalid free
- ESBMC used to extract verification conditions (e.g., conditions of memory safety violation)
- program is then instrumented convert memory safety to assertions about pointers
- tests are executed (with concrete data)

Threader~\cite{Gupta2011}
- compositional verification of parallel programs, thread-modular proofs for C programs
- Horn clause encoding
- uses compositional proof rules for concurrent programs~\cite{Jones1983,Owicki1976}
- abstract reachability + refinement
- not limited to specific synchronization primitives
- safety (assertions), can also prove termination properties

\section{Abstraction-Based Techniques}

\section{Systematic Testing}

\section{Control-Flow Analysis Techniques}

\section{??? Termination and Temporal Logics}

- sequential LTL (inf systems, inc. termination analysis): \cite{Dietsch2015}
- other liveness in sequential C (inf sys, Terminator): \cite{Cook2007} (drivers)
- termination (seq, ptr, inf, \textsc{Terminator}): \cite{Cook2006}
- termination (inc. heap): \cite{Berdine2006}
- termination+nontermination (C, Java, Haskell, Prolog, recurstion, ptr, bitvectors (bit-precise); seq no structs): AProVe \cite{Hensel2017, Giesl2017}

T2~\cite{Brockschmidt2016}
- open source release of the Terminator
- liveness + safety
- no concurrency, heap, recursion

\section{XXX}

\section{Real-World Parallel Programs}


\section{Relaxed Memory Models}

There are numerous techniques for analysis of programs with respect to relaxed memory.

\paragraph{Verification of Absence of SC Violations}

For these methods, the question is whether a program, when running under a relaxed memory model, exhibits any runs not possible under sequential consistency.
This problem is explored under many names, e.g. (TSO-)safety~\cite{Burckhardt2008}, robustness~\cite{Bouajjani2013,Derevenetc2014}, stability~\cite{Alglave2011}, and monitoring of sequential consistency~\cite{Burnim2011}.
A similar techniques are used in \cite{Yang2004} to detect data races in Java programs.
A related problem of correspondence between a parallel and sequential implementation of a data structure is explored in~\cite{Ou2017}.
Some of these techniques can also be used to insert memory fences into the programs to recover sequential consistency.

Neither of these techniques is directly comparable to our method.
For these techniques, a program is incorrect if it exhibits relaxed behavior, while for us, it is incorrect if it violates specification (e.g., assertion safety and memory safety).
In practice, the appearance of relaxed behavior is often not a problem, provided the overall behavior of the data structure or algorithm matches desired specification.
In many lock-free data structures, a relaxed behavior is essential to achieving high performance.

\paragraph{Direct Analysis Techniques}

There are multiple methods for analysis of relaxed memory models based on program transformation.
In~\cite{Alglave2013} a transformation-based technique for the x86, POWER, and ARM memory models is presented.
Another approach to program transformation is taken in~\cite{Atig2011}, in this case, the transformation uses context switch bounding but not buffer bounding, and it uses additional copies for shared variables for TSO simulation.
In~\cite{Abdulla2017} the context-bounded analysis using transformation is applied to the POWER memory model.
Our work in~\cite{SRB15weakmem} presents a transformation of LLVM bitcode to simulate buffer-bounded \xtso runs; compared to this work it has significantly less efficient implementation of the \xtso simulation.


So far, all of the described techniques used some kind of bounding to achieve efficiency -- either bounding number of reordered operations, number of context switches, or number of iterations of loops.
An unbounded approach to verification of programs under TSO is presented in~\cite{Linden2010}.
It uses store buffers represented by automata and leverages cycle iteration acceleration to get a representation of store buffers on paths which would form cycles if values in store buffers were disregarded.
It does not, however, target any real-world programming language.
Instead, it targets a modified Promela language~\cite{Holzmann1997}.
Another unbounded approach is presented in~\cite{Bouajjani2015} -- it introduces TSO behaviors lazily by iterative refinement, and while it is not complete, it should eventually find all errors.

\paragraph{Other Methods}\label{other-methods}

In~\cite{Park1995}, the SPARC hierarchy of memory models (TSO, PSO, RMO) is modeled using encoding from assembly to Mur\(\varphi\)~\cite{Murphi}.
In~\cite{Huynh2006} an explicit state model checker for C\# programs (supporting subset of C\#/.NET bytecode) which uses the .NET memory model is presented.
The verifier first verifies program under SC and then it explores additional runs allowed under the .NET memory model.
The implementation of the exploration algorithm uses a list of delayed instructions to implement instruction reordering.
The work~\cite{Dan2013} presents verification of (potentially infinite state space) programs under TSO and PSO (with bounded store buffers) using predicate abstraction.

A completely different approach is taken in~\cite{Turon2014}.
This work introduces a separation logic GPS, which allows proving properties about programs using (a fragment of) the C11 memory model.
That is, this work is intended for manual proving of properties of parallel programs, not for automatic verification.
The memory model is not complete; it lacks relaxed and consume-release accesses.
Another fragment of the C11 memory model is targeted by the RSL separation logic introduced in~\cite{Vafeiadis2013}.

\section{Termination of Parallel Programs}

For the related work, we consider only results which go beyond safety checking.
There are many approaches to find problems such as assertion violations or memory safety violations, but they are fundamentally limited to properties concerning finite runs of the program, and we are focusing here on an infinite behaviour, namely on the absence of termination.
Similarly, we do not mention techniques which specialise on checking sequential programs and have no support for parallelism, as well as techniques which are tailored to a specific modelling language and cannot be applied in general.

Several techniques for checking properties other than safety exist -- indeed
usage of various temporal logics, such as Linear Temporal Logic (LTL)
\cite[Chapter 5]{PoMC} and Computation Tree Logic (CTL) \cite[Chapter 6]{PoMC} in the context of model checking dates way back to the beginning of research in formal methods.
Unfortunately, these techniques are not often applied to programs written in real-world programming languages such as C and C++.

As for techniques which detect nontermination, both static and dynamic
techniques exist for the detection of deadlocks caused by circular waiting for
mutexes~\cite{CC14,agarwal2010detection,bensalem2005scalable}.
However, these techniques specialise on mutexes and do not allow general nontermination detection, and it is unlikely that they could be naturally extended to cover it.
There are also techniques that detect deadlocks of the whole program (i.e., a program state from which the program cannot move) \cite{Chaki2005,Demartini99}, but these techniques cannot find cases in which only some threads of the program are making progress, while other threads are blocked forever.
Also, these global deadlock detection techniques are inadequate in the presence of synchronisation mechanisms which causes busy waiting instead of blocking (for example spin locks) or in the cases when normally blocking operations are implemented using busy waiting (which can be easier to handle for the verifier in some cases).
A somewhat different approach based on communicating channels is proposed in \cite{Ng2016}, but this approach is aiming at the Go programming language which primarily uses shared channels for communication between threads.
Overall, neither of these techniques is applicable in general for the detection of nontermination in programs which use a combination of synchronisation primitives in shared memory.
Finally, there are also techniques for checking termination of sequential programs, to name a few \cite{Giesl2017,Chen2018}.

\section{Termination Checking}

SACO~\cite{Albert2017}
- for analysis of concurrent programs with loops
- uses may-happen-in-parallel analysis to infer which part of the program can interfere
- also infer upper bounds on iteration numbers
- for modelling language (with shared memory)
- generates constraints on how the shared state can be modified in order for the loop to terminate and than checks that this will eventually hold

2LS~\cite{Malik2020,Malik2018,Chen2017}
- built on CPROVER (the backend of CBMC)
- interprocedural termination analysis for sequential programs
- bounded model checking with k-induction and abstract interpretation
- sequential C programs
- bit-precise
- assertions, (non-)termination
- template-based synthesis for invariants and ranking functions
- shape domain for heap analysis
  - shape and content of the dynamic memory
  - takes address reuse into account
  - combination of abstract domains
- termination analysis based on lexicographical linear orders
- simple nontermination proofs for loops (repeated loop state; loops which iterate over numerical variables with constant increments in a way they cannot end)
- no recursion, arrays, concurrency

Arctor~\cite{Kupriyanov2014}
- for concurrency
- based on abstraction and refinement
- based on well-founded relations
- can show termination, or possibly non-terminating execution


~\cite{Cook2007thr}
- Other threads are abstracted into a model of environment which is incrementally refined
- termination proving for threads (thread termination proving)


\section{Benchmark Suites}

- \cite{Sarkar2011,MadorHaim2012} POWER tests
- http://www.cprover.org/wmm/
- ESBMC (\cite{Cordeiro2011}): http://users.ecs.soton.ac.uk/lcc08r/esbmc/
- ESBMC++ \cite{Ramalho2016:19,6,27,.} (sec. IV.A. Experimental Setup)
- BLITZ:
  - Bugbench: % https://scholar.google.com/scholar?as_q=Bugbench%3A+Benchmarks+for+evaluating+bug+detection+tools&as_occt=title&hl=en&as_sdt=0%2C31
  - tools from http://www.isc.org/

\section{MISC}

- need for environemnt and application intefrace modelling: \cite{Cordeiro2016}

% vim: colorcolumn=80 expandtab sw=4 ts=4 spell spelllang=en
