Historically, automatic analysis techniques for parallel programs started with
analysis of models of systems.
A programmer wishing to use such a tool would either start by creating a model
of the system (in the specification step of the development), and then provide
an executable implementation for this model or, if they already had a working
product, they would have to create a model in order to analyze it.
Such tools include for example SPIN~\mcite{Holzmann1997}, older versions of DIVINE~\mcite{BBCS05}, LTSmin~\mcite{Kant2015} and BMC~\mcite{Biere1999}.
Such an approach requires an extra investment in the modelling phase and, even
if analysis of the model concludes it is correct, it does not prove that the
final product is indeed correct.

Later, with the improvement of both analysis techniques, as well as overall
improvement in available computing power, tools which analyse programs written
in mainstream programming languages become available.
Early examples of such tools are Java Path Finder~\mcite{Visser2003} (an explicit-state model checker for Java) and CBMC~\mcite{Clarke2004} (a SAT-based bounded model checker for C).
Since 2012, the Software Verification Competition (SV-COMP) \mcite{Beyer2020svc}
aims to showcase tools which support direct verification of software written in
C and later also Java.
While it includes mostly sequential programs, there is also a subcategory for
parallel C programs in SV-COMP.

We will now focus in more details on automatic techniques for verification of
parallel programs.
We will not consider program analysis techniques which require substantial manual effort (e.g., proof-theorem-based techniques), or techniques which are not applicable to realistic programs (e.g., techniques which use a special modelling language).
We will also mostly disregard tools with no support for parallel programs.

\section{Explicit-State Model Checking}

Explicit-state model checking is based on exhaustive exploration of the
state-space graph.
It checks that a given (finite-state) system satisfies given property.
The property is often given by an LTL formula and the automata-based approach
to LTL verification is used (i.e., the problem is reduced to the problem of
repeated reachability of a state in the state-space graph)~\mcite[\S
5.2]{Baier2008}.
In the special case of safety properties, it is sufficient to perform graph
search for a state which violates the safety property, for example using the
depth-first search algorithm, or any other graph search.

The advantage of explicit-state model checking is that it is conceptually easy
to apply it to verification of parallel programs (under sequential
consistency), as the interleaving semantics of thread naturally gives rise to
the state space graph.
Furthermore, explicit-state model checking does not require the program to be terminating, it is sufficient that its state space is finite.\mnote{A finite state space can contain cyclical infinite behaviour -- a loop in the state space.

\medskip
\begin{tikzpicture}[>=latex,>=stealth',auto,node distance=2cm,semithick,initial text=]
  \node[state,initial] (t) {$x$};
  \node[state] (f) [right of = t] {$\lnot x$};

  \path[->, shorten >=1pt]
	(t) edge[bend left] (f)
	(f) edge[bend left] (t)
  ;
\end{tikzpicture}
}

\paragraph{State Space Explosion \& Reduction Techniques}

In practice, explicit-state model checking is prone to the \emph{state-space
explosion} problem: the number of states in the state-space graph of a
reasonable system can easily be so big it is not possible to store the state
space in the available memory and explore the state space in reasonable time.
Since the algorithm which explores the state-space graph needs to detect which
states were already seen to ensure termination (and to check for LTL
properties), available memory is often the limiting factor, at least without
advanced state space reduction techniques.

To mitigate state-space explosion, several state-space reduction techniques
were introduced.
Using these techniques, it is possible to explore only some of the states of
the state space in such a way that the property holds for these states if and
only if it holds for the entire state space.
One of these techniques is \emph{Partial Order Reduction} (POR), which
can eliminate some states by exploring independent events only in one
particular order~\mcite{Peled1993,Godefroid1996partial}.

Another wide family of reductions are reductions which can coalesce a path in a
state space into a single edge and hide all intermediate states.
This idea was introduced by Lipton in~\mcite{Lipton1975}, who introduced the
notion of right movers (``resource acquire operations'') and left movers
(``resource release operations'') to identify statements in program which can
be executed atomically.
However, in analysis of realistic parallel programs a notion of instruction (or
action) visibility is often used -- a group of instructions from one thread can
be executed atomically provided that at most one of them is observable by the
other threads and that this grouping does not influence checking of the
verified property or termination of the search.
Both static and dynamic reduction methods were proposed, under many names,
including D-reduction~\mcite{Lipton1975}, path reduction~\mcite{Yorav2004}, $\tau$ reduction~\mcite{BBR2012} for the static variants and $\tau+$ reduction~\mcite{RBB13} and \mcite[Section 6]{RSCB2018} for the dynamic once.
The reductions are also often used without naming the technique, for example in
Java Path Finder~\mcite{Visser2003}.
Quite naturally, the dynamic methods are better suited for the complex control-
and data-flow of realistic programs.

Both partial order reductions and path reductions are often also used in tools
based on other principles then explicit-state exploration.

Additionally, there are variants of \emph{symmetry reductions} which reduce the
state space by coalescing states which differ only in properties not relevant
for the program analysis \cite{Clarke1998}.
For example the \emph{heap-symmetry} reduction allows to consider two states
that differ only in the order in which memory objects were allocated to be the
same~\mcite{RBB13}, \mcite[Chapter 6]{RSCB2018}.
A dead-variable elimination~\mcite{Yorav2004} can be also seen as an instance of symmetry reductions.

These state space reduction techniques can reduce the number of states by
several orders of magnitude~\mcite{RBB13}, and therefore enable verification of
realistic (but still relatively small) programs.

Interestingly, the proposed reduction techniques which aim to preserve verified
properties are not always correct, for example the original version of $\tau+$
reduction considered only stores to be visible, but it was later shown that
repeated loads have to be also visible (shown by me in~\mcite{S2016}, fixed in
\mcite[Section 6]{RSCB2018}).\begin{marginnote}%
Consider this program with threads \texttt{t0} and \texttt{t1}:

\begin{cppcode}
  int x = 0;
  void t0() {
    x = 1;
  }
  void t1() {
    int a = x;
    assert(a == x);
  }
\end{cppcode}

The assertion is violated if \cpp{t0} executes between the (local, invisible)
assignment and the assertion in \cpp{t1}.
However, if repeated loads are not considered visible, they are coalesced and
the assertion is not violated.
\end{marginnote}
%
Similar problem was present in \mcite{Cordeiro2011} where ESBMC could perform two conditional jumps which read the same shared variable with no context switch between them (section 3.1, rule R3).
Interestingly, the authors notice the possibility of missing context switches, but only introduce an option to fix it, leaving the problematic behaviour as default.

To further improve capabilities of explicit-state model checking, several
techniques for memory-efficient representation of the set of visited states
were introduced.
These techniques include \emph{hash compaction} and \emph{bitstate
hashing}~\mcite{Holzmann1998}, which are incomplete techniques that store
hashes of states instead of storing the entries states (and therefore can omit
some parts of the state space if there is hash collision),
\emph{conditional and external storage of states}~\mcite{Hammer2007}, and
\emph{lossless compression techniques}~\mcite{RSB15TC,Laarman2019}.

\paragraph{Data Nondeterminism}
While explicit-state model checking can easily represent control-flow
nondeterminism, it is not well suited for data nondeterminism, as it is not
practical (or even possible) to explicitly enumerate all possible values of
data domains.
Therefore, if data nondeterminism is required, explicit-state model checking
needs to be combined with some technique for symbolic of abstract data
representation.

\paragraph{Tools}

The pioneering tool is the SPIN LTL model
checker~\mcite{Holzmann1997,Holzmann2004}, however, it has a very limited
support for analysis of realistic programs.
SPIN targets a parallel modelling language PROMELA, which has support to embed
C code to define atomic an atomic step.
In~\mcite{Zaks2008} SPIN was extended to have partial support of C with the
need to define a test driver in PROMELA.

Java Pathfinder (JPF)~\mcite{Artho2019,Visser2003} is an explicit state model
checker (with symbolic extensions) for Java and JVM-based\mnote{Java is
not executing directly on the target hardware but instead uses an intermediate
language which is executed by JVM. Other languages (e.g., Scala, Kotlin) can
also target JVM and share the intermediate representation with Java.}
languages.
From its beginning JPF targets parallel Java programs.
It checks for safety properties, namely for uncaught exceptions which in Java also subsume assertion checking and bound checking.
To reduce state space, JPF uses hash-compaction (and therefore under-approximates all possible behaviours), symmetry reduction (with respect to class loading order and heap symmetry), optionally predicate abstraction (with user-provided predicates), partial order reduction, and groups instructions with local effects.
Interestingly, the instruction grouping in JPF uses a heuristic which can cause it to miss some behaviours.
JPF has also model of parts of the Java standard library (including limited IO
support) and limited support for execution of native code from the Java
code\mnote{Java programs can use the Java Native Interface (JNI) to interfere
with native code, for example in order to access operating system primitives
directly.}
In addition to scheduling nondeterminism, JPF can use explicit choice as an
additional source of nondeterminism.
The symbolic extension, Symbolic Pathfinder (SPF)~\mcite{Pasareanu2013,Noller2019} adds
support for symbolic data representation using symbolic execution.
It supports test generation and detection of assertions and errors related to parallel execution.
It primarily targets unit tests and sub-system level testing and has a
possibility to use unit preconditions and combine symbolic and explicit
execution.
To explore different possible interleavings, SPF uses the explicit JPF without
state comparison and with depth bound to ensure termination (the state
comparison can be enabled but then disregards the symbolic data and therefore
can miss many behaviours).
Interestingly, SPF is able to handle certain cases of dynamically allocated
linked symbolic data by \emph{lazy initialization} -- when a symbolic pointer
is accessed it can be expanded to either null pointer or another node of
symbolic data~\mcite{Khurshid2003}.
SPF has support for symbolic arrays~\mcite{Fromherz2017} and symbolic strings~\mcite{Bang2016}.

DIVINE~\mcite{DIVINEToolPaper2017} is an explicit-state model checker developed
by our research group.
Historically it targeted several modelling languages for parallel systems and
LTL verification using parallel and distributed algorithms, but later it
shifter towards analysis of C and C++ using the LLVM intermediate language.
While it now aims primarily at verification of safety properties (assertion
violations, memory access safety, detection of use of undefined variables,
detection of memory leads, numeric manipulation errors, and deadlock-freedom for
the POSIX mutexes) it has also limited support for LTL and there is also an
extension for detection of nontermination in parallel programs
(\autoref{chap:lnterm}, \mcite{SB2019}).
To tackle realistic programs, DIVINE uses a dynamic detection of invisible
actions ($\tau+$ reduction) and an efficient representation of program memory
which facilitates heap-symmetry reduction and state-space
compression~\mcite{RSCB2018}.
DIVINE has also support for symbolic and abstract data representation using
program transformations~\mcite{LRB2018}.
Currently it supports symbolic bitvector manipulations for integers and floats
and symbolic string representation~\mcite{CLOR2019}.
With the symbolic data representation using bitvectors, DIVINE uses SMT solvers
to check for feasibility of traces and to compare symbolic states -- this way
it retains the ability to join states which are semantically equivalent even if
the symbolic data are represented by a different formula.
This allows DIVINE with symbolic data to ensure termination for programs with
finite symbolic state space and allows LTL properties.
One of the main goals of DIVINE is to support verification of C and C++
programs which use existing libraries.
To this end, DIVINE has almost complete standard C and C++ libraries (as of
C++17), the POSIX thread library (\texttt{pthreads}), and it also supports C++
exceptions (\autoref{chap:lang}, \mcite{SRB2017}).
To reflect behaviour of parallel programs on contemporary hardware, DIVINE
has also support to analyse programs with respect to the \xtso memory
model~(\autoref{chap:mm}, \mcite{SB2018x86tso}).
DIVINE has also an in-built compiler based on LLVM's clang and support for
significant parts of POSIX filesystem and process APIs~\mcite{RBMKB2019}.

Another explicit-state model checker from our research group is
\textsf{SymDIVINE}~\mcite{MBLB2016} which combines explicit control flow
handling with symbolic representation of data using bitvectors (with symbolic
state equality).
\textsf{SymDIVINE} targets safety and LTL properties in C programs.
This tool is now discontinued in favor of aforementioned symbolic data support
in DIVINE.

% LTSmin~\cite{Kant2015}
% - probabilistic, timed systems
% - multi-core LTL model checker, partial order reduction
% - multi-core symbolic checking for $\mu$-calculus
% - multiple modelling formalism, but no realistic programming languages
% - state space compression
% - paralell LTL search

\section{Stateless Model Checking}

Compared to explicit-state model checking, \emph{stateless model checking}
(SMC) avoids storing the set of visited states and therefore has decreased
memory consumption.
Furthermore, since the state representation is not required to be as compact as
possible, stateless model checker can have simpler representation of states.
Stateless model checking was introduced in~\mcite{Godefroid1997}, it aims at
safety analysis of terminating realistic parallel programs.
A stateless model checker usually explores the state space in depth-first
manner and it can explore some parts of the state space multiple times (since
it does not store the set of visited states).
Therefore, the requirement that input program is terminating is necessary to
ensure the verification procedure terminates.
In practice, this requirement is often ensured by imposing loop iteration
bounds -- loops are assigned maximum allowed number of iterations, if the
program under test requires more iterations of some loop, the loop bound can be
increased, or the analysis can be terminated as inconclusive.

Stateless model checking is also sometimes presented under names like \emph{systematic concurrency testing}~\mcite{Christakis2013}.

\paragraph{State Space Reductions}

Without additional state space reductions, SMC would lead to redundant
explorations of many parts of the state space -- in parallel programs it is
common that two or more actions of different threads are independent and
regardless of their order they lead to the same end state.
In this case a stateless model checker would explore a state as many times as
is the number of paths from the initial state to this state (in the worst case
the number of paths to a given state can be exponential to its distance from
the initial state).
To mitigate this problem, \emph{dynamic partial order reduction}
(\emph{DPOR})~\mcite{Flanagan2005dpor} is often employed with SMC.
DPOR is a version of partial order reduction that tightly integrates with
the SMC exploration algorithm and keeps track of parts of the state space which
still need to be explored.
Using DPOR, SMC can avoid redundant exploration of equivalent paths in the
state space.

Many works are concerned with design of efficient DPOR methods both for
parallel programs running under sequential consistency (interleaving
semantics), and for various relaxed memory models.
This is usually accomplished by combination of two aspects: an equivalence of
traces and an exploration algorithm which ensures at least one trace (and in
optimal case exactly one trace) from each equivalence class is explored.
The trace equivalence has to be designed in such a way that for each of its
classes either all traces contain only safe states or all traces contain an
unsafe state -- i.e., the equivalence preserves safety properties.

Over the years, multiple DPOR techniques were introduced
\mcite{Flanagan2005dpor,Sen2007,Tasharofi2012,Saarikivi2012,Abdulla2014,Zhang2015,Chalupa2017,Abdulla2018,Aronis2018,Abdulla2019}.
Among these \mcite{Abdulla2014} is interesting since it provides an optimal algorithm for equivalence based on \emph{Mazurkiewicz traces} \mcite{Mazurkiewicz1987} (where traces are considered equivalent if one of them can be obtained from the other by swapping adjacent non-conflicting execution steps).
However, the optimal DPOR presented by \mcite{Abdulla2014} is optimal for the
given trace equivalence (i.e., it explores exactly one execution in each equivalence class of the used trace equivalence).
In recent years, several works have explored coarser equivalences and optimal algorithms for them.
In \mcite{Chalupa2017} the authors use a notion of observation of write operations and an consider traces to be equivalent if the corresponding reads observe the same writes in both traces, however, their algorithm is optimal only for programs in which the graph of intra-thread communication is acyclic. 
A similar notion of observation is used in \mcite{Aronis2018}, in this case to only consider write events as interfering if at least one of them can be observed later.
In \mcite{Abdulla2018} the authors use a notion of reads-from equivalence (i.e., trace equivalence based on program order and reads-from relation which connects reads to writes which produced the read value) for analysis of a fragment of the C11 memory model which contains only relase and acquire memory orders.
The advantage of this trace equivalence is that it does not distinguish traces which differ in order of unobserved writes.
The authors argue that working with this equivalence is easier for release-acquire ordering than for sequential consistency due to complexity of checking if a reads-from relation can correspond to a run of a program.
The same trace equivalence is used in \mcite{Abdulla2019} for sequentially-consistent programs.
To avoid the need for expensive (NP-complete) checks for consistency of reads-from relations, the authors use two incomplete but polynomial algorithms, one which can show that given relation is consistent and one which can show it is inconsistent, before running the expensive check which is exponential in the number of threads.

Another reduction approach based on observation of read and written values is
\emph{Maximal Causality Reduction} (\emph{MCR})~\mcite{Huang2015}, which can be
seen as an alternative to DPOR.
MCR employs an SMT solver to find new traces to explore, which allows it to
explore less interleavings then Mazurkiewicz-trace-based DPOR techniques.
Each time a new trace is found it is guaranteed that at least one read will read a different value than read on already observed traces.
An advantage of MCR is that it can be easily modified for parallel
exploration (DPOR cannot be easily executed in parallel).
The MCR was also applied to the TSO and PSO memory models \mcite{Huang2016}.

% \TODO{RCMC?} \mcite{Kokologiannakis2017}

\paragraph{Data Nondeterminism}

In most works, stateless model checking with DPOR expects that the thread
scheduling is the only source of nondeterminism in the system \mcite{Flanagan2005dpor}.
However, there are combinations of SMC with other techniques which can handle
nondeterministic data.
In \mcite{Saarikivi2012} a combination of DPOR with concolic execution is presented.
Another combination of concolic execution with SMC is presented in \mcite{Sen2007}, this one uses a different approach to DPOR then \mcite{Flanagan2005dpor}.

\paragraph{Tools and Techniques}

VeriSoft \mcite{Godefroid1997,Godefroid2005verisoft} the pioneering tool of stateless model checking.
It aims at safety verification of realistic parallel programs, primarily in C and C++, but also in other programming languages -- VeriSoft works with compiled executable programs and uses a custom scheduler to explore (bounded) runs of these programs.
To limit re-exploration of states and state space size, VeriSoft allows scheduling only on visible operations and uses partial order reduction.

jCUTE \mcite{Sen2007} is a tool which combines concolic execution and stateless model checking for Java programs, which allows it to handle both parallelism and data nondeterminism.
To explore all possible behaviours of parallel programs, jCUTE detect data races (concurrent access of two threads to the same location, at least one of which is a write or a lock operation) and rearranges schedules which led to them.
% - assumes locks are disjoint from R/W memory locations

CHESS \mcite{Musuvathi2008} an SMC tool which uses a custom scheduler to drive execution of compiled executable programs mainly in C, C++ and .NET languages (such as C\#).
It uses binary instrumentation to control programs' scheduling and record order of events.
To limit state space explosion it explores runs with fewer context switches first and uses a cache of happens-before graphs of events to avoid redundant explorations (and therefore is not truly stateless).
To handle the environment of the operating system better, CHESS can record and relay environmental values such as current time, process identifiers and output of platform's random number generators.
However, the user must ensure that other parts for the environment (e.g., filesystem, network) is used in such a way that the program is executes the same way if the same thread scheduling is repeated.
The authors argue that this approach is practical for most unit tests.

LCT \mcite{Saarikivi2012,Kahkonen2013} is another tool which combines concolic execution and SMC to handle parallel Java programs with data nondeterminism.
It uses program instrumentation to add symbolic operations where needed and allows scheduling to happen only on visible operations.
To speedup the analysis, LCT can run multiple executions of the program with different inputs in parallel distributed over the network.

CDSChecker \mcite{Norris2013} is a stateless model checker for C and C++ with support for the C11/C++11 memory model (with exception of release-consume synchronisation and out-of-thin-air values\mnote{Which are discouraged by the standard, but the C11/C++11 memory models allow them.}).
It can simulate load speculation and delays by forwarding stored values to previous loads and validating this speculation.
According to the authors, CDSChecker primarily aims to help with unit testing concurrent data structures.

Concuerror \mcite{Christakis2013,Abdulla2014,Aronis2018} is an SMC for Erlang programs.
In Erlang, the primary way of communication between processes is message passing.
Concuerror uses context bounding and it has also an implementation of optimal DPOR for Mazurkiewicz traces and optimal DPOR based on observers.

SATCheck \mcite{Demsky2015} is a stateless model checker for C programs with support for sequential consistency and TSO.
It records dependencies between program events and uses SAT solver to reorder the events on a concrete run to get new interleavings with new behaviour.

rInspect \mcite{Zhang2015} is a LLVM-based stateless model checker for C
programs running under the TSO and PSO relaxed memory models.
It uses store buffers and shadow threads that flush values from store buffers
to the main memory.
Store buffers can be optionally bounded.
The shadow thread approach allows it to use existing DPOR techniques designed
for sequential consistency.

The maximal causality reduction (MCR) is implemented in an unnamed tool for analysis of Java programs \mcite{Huang2015,Huang2016}.
It supports both sequential concurrency and the TSO and PSO relaxed memory models.

Nidhugg \mcite{Abdulla2016,Abdulla2017tso,Aronis2018,Abdulla2019}, is a stateless model
checker which focuses on C programs running under relaxed memory models. It
has support for sequential consistency, TSO, PSO, POWER, and partially ARM
memory models.
For TSO and PSO, Nidhugg uses the optimal DPOR algorithm from \mcite{Abdulla2014} to explore exactly one execution from each equivalence class given by \emph{chronological traces} that capture dependencies between memory operations.
The combination of chronological traces and optimal DPOR algorithm means that
for programs which do not exhibit relaxed behaviour under TSO/PSO, Nidhugg
explores the same number of traces under TSO/PSO as it would explore under
sequential consistency.
For POWER, Nidhugg uses a different algorithm which can perform a redundant exploration of incomplete traces, but does not generate redundant complete traces (for the trace equivalence given by Shasha-Snir traces~\mcite{Shasha1988}).
Nidhugg has also option to use a \emph{reads-from}-based trace equivalence for sequential consistency, together with an optimal exploration algorithm for this equivalence.
This equivalence does not distinguish traces which differ only in order of conflicting writes and therefore can be exponentially more coarse.
The corresponding algorithm needs to decide if a given read-from relation is consistent, which is a NP-complete problem.
However, the authors show that the expensive check can be avoided in most cases by use of faster but incomplete checks.
Nidhugg uses LLVM to avoid the cost of direct analysis of C programs.

% \mcite{Abdulla2019}
% - coarser equivalence for SC
% - efficient in practice
% - uses equivalence based on seqeunces of events for each thread and reads-from relation between them
% - checking consistency of a given reads-from relation is NP-complete -- the exploration algorithm first uses two incomplete but faster checks (to detect inconsistency and consistency)
%   - on all programs they tesed the incomplete checks were sufficient

RCMC \mcite{Kokologiannakis2017} is a stateless model checker for C and C++ running under the RC11 memory model \mcite{Lahav2017} (which is an attempt to formalize and fix the C11 memory model).
Instead of exploring interleavings, the tool uses execution graphs which represent visible program actions and dependencies between them.

Tracer \mcite{Abdulla2018} is a tool for analysis of the release-acquire fragment of the C11/C++11 relaxed memory model.
I can work with C and C++ program which do not use any other atomic orderings then release and acquire, i.e., it has no support for sequentially consistent atomics or relaxed atomics.
Tracer does not explore all possible orderings of conflicting writes, instead, the equivalence relation at the core of their DPOR implementation is given only by program orders and read-from to avoid redundancy.
The proposed exploration algorithm is optimal for traces defined on this equivalence.
In practice this means that nondeterministical decision takes place at read operations and writes are only recorded, with the addition of backtracking for cases when a previous read might read from a later executed write.
% - C/C++11 -- replaces implementations of atomic, threads, mutex to drive execution

\paragraph{X}

% \mcite{Aronis2018}
% - optimal dpor of \mcite{Abdulla2014} extended with observability -- the order of write operations only needs to be considered if someone observes the difference], interference is optional
% - Nidhugg and Concuerror


SATABS (unknown type)
- according to \cite{Cordeiro2011} cannot handle arrays + arithmetic





\section{Bounded Model Checking \& Related Techniques}

Bounded model checking (BMC) was introduced in~\cite{Biere1999} as an alternative to
symbolic model checking techniques which used binary decision diagrams.
BMC encodes program runs of fixed length into propositional formulas, or
formulas over some first-order logic.
Then in relies on SAT or SMT solvers to decide if the formula is satisfiable or
not.
One of the advantages of BMC is that is naturally handles data nondeterminism.

The original paper introducing BNC presented a verification procedure for LTL
(which detected loops in the program runs by checking equality of the last
state of the bounded run to some of its previous states).
However, for realistic programs the focus is mainly on safety properties, and
more recently also on (non)termination.\mnote{For tools which use approximation
or heuristics, checking for termination is not the same as checking for
nontermination as the tool might simply return \emph{unknown} result if it
fails to prove its objective (i.e., termination or nontermination).}

\TODO{Most BMC tools build formula from SSA form of the program… 
+ bound on the number of times each loop might be executed (unwinding),
bounded recursion depth
… Rabinovitz2005}

We have identified three broad approaches to support of concurrent programs in
BMC.
The conceptually simplest is to explicitly enumerate symbolic context-switch
bounded runs of the program and then encode them to resolve symbolic data.
This is the approach used by ESBMC~\cite{Cordeiro2011} and by
\cite{Rabinovitz2005} for an early concurrent extension of CBMC.
Another approach is to encode control flow of threads separately and add scheduling constraints which specify inter-thread ordering.
This approach is used by CBMC~\cite{Alglave2013po} and also proposed in~\cite{Ganai2008}.
The last approach is sequentialization, which makes use of a BMC for sequential programs and a pre-processing step which converts a parallel program into a nondeterministic sequential program.
Many sequentialization schemes were proposed, differing both in the size of the encoding and the way they limit thread interaction (e.g., limit to the number of context switches, to the number of shared-variable interactions, …)~\cite{Qadeer2004?,TODO...}.

The main limitation of BMC is that it explores only runs up to some length
bound $k$.
Therefore, BMC alone cannot prove correctness unless it shows that the loop
bound was sufficient (for example by inserting a special \emph{unwinding
assertions} into the program and showing they are not violated).
To mitigate this limitations BMC can be combined with other techniques which
aim to prove correctness of the program, such as $k$-induction~\cite{TODO} or
IC3~\cite{TODO}.

\paragraph{$k$-Induction}

$k$-induction~\cite{Donaldson2011,Gadelha2017} is an extension of
bounded model checking which allows it to find bugs faster and to prove
correctness of programs without unwinding loops fully.
Multiple $k$-inductions schemes exists, in the one proposed in~\cite{Gadelha2017} a verifier with $k$-induction repeatedly performs three steps with an increasing bound $k$.
\begin{description}
    \item[Base Case] checks if an error is reachable in $k$ steps.
    \item[Forward Condition] checks if all program's paths had terminated in
        $k$ steps (i.e., the verification is done as the tool had already
        explored all states).
    \item[Inductive Step] checks that if the property holds for the first $k$
        steps, it also holds for the $k+1$ steps.
        This is checked in a modified program in which all loop variables are
        initialized to nondeterministic values before the loops and the loops
        are required to execute to completion.\mnote{This can be achieved by
        instrumenting \texttt{assume} statements which ensure that the loop
        body is entered and that after the given number of iterations the
        condition for loop termination holds.}
\end{description}
\TODO{Nested loops are unwound recursively}
One of the problems with $k$-induction is that the induction argument is not strong enough to prove the inductive step.
For this reason, the induction can be strengthen by invariants derived from the original program (i.e., the nondeterministic values of loop variables are constrained by the invariants).

\paragraph{IC3} \TODO{TODO}


\paragraph{Tools}

The original bounded model checker BMC~\cite{Biere1999} was an LTL bounded
model checker which targeted a modelling language.


CBMC~\cite{Clarke2004,Kroening2014} is a widely used SAT-based bounded
model checker for sequential and parallel C programs.
It uses bit-precise encoding and therefore preserves semantics of computer
integers.
CBMC can detect safety errors, it uses instrumentation for detection of errors
other then assertions.
For efficient analysis of parallel programs CBMC uses encoding based on partial
orders described in~\cite{Alglave2013po} -- it builds the formula from the SSA
form of each thread and ordering constraints for shared variables.
CBMC is notable for its support of relaxed memory models, including \xtso,
POWER memory model and sequential consistency~\cite{Alglave2013po}, \TODO{cite
more…}.

\TODO{
CBMC \cite{Kroening2014,Clarke2004}
- parallelism, weak (SC, x86, POWER), uses partial orders  for efficient encoding of parallelism \cite{Alglave2013po} instead of interleavings (\TODO{? :30, :36, :6})
- relaxed memory has little impact on performance
- SC: \cite{Alglave2013po:25}
- k-induction?? (\cite{Gadelha2018:7})
}

ESBMC~\cite{Gadelha2018,Gadelha2019}, is another widely used BMC for C
programs in which it can detect assertion violations, memory errors, overflows and \TODO{mutex-caused} deadlocks.
ESBMC was derived from CBMC, it uses SMT for encoding of the program and has
support for $k$-induction with invariant generation (based on interval analysis
of integral variables; the invariant generation is currently unsound for
programs with pointers).
The support for concurrency in ESBMC is described in~\cite{Cordeiro2011}.
Interestingly, ESBMC explores possible program interleavings explicitly and
doing so it collects constrains on nondeterministic variables, which are then
used to generate a formula.
The formula can be generated and solved either for each run separately (lazy
approach), which has the advantage of being incremental, or all interleavings
can be encoded into one formula (schedule recording) which uses guards to
encode scheduling of each interleaving.
There is also encoding based on under-approximation and widening which attempts
to produce more compact encoding.
The approximation uses proofs of unsatisfiability of the formula for refinement.
The lazy approach seems to work best according to~\cite{Cordeiro2011}.
Regardless of the formula encoding, ESBMC uses bound on the number of context
switches.
In order to limit number of runs which need to be explored, ESBMC allows
context switches only at visible instructions (i.e., instructions which access
shared memory).
The handling of parallelism in ESBMC makes it closely related to explicit-state
model checkers with symbolic extensions, like Symbolic Pathfinder or DIVINE.
Similarly to CBMC, ESBMC used a custom C parser, but it had later switched to
using the clang compiler for parsing C and C++.
Unlike other tools which use clang, it does not use the LLVM intermediate
representation, but instead builds its own internal representation based on the
C/C++ AST produced by clang.

ESBMC has also derivatives which aim at C++ verification.
ESBMC++~\cite{Ramalho2013} uses a model of parts of the standard C++ library,
has support for C++ exceptions and inheritance.
$\text{ESBMC}^{\textit{Qt}OM}$~\cite{Sousa2015,Garcia2016} adds a model
of parts of the Qt framework for C++ programs.
In both cases the models approximate behaviour of the respective libraries
based on the standard or documentation.

JBMC~\cite{Cordeiro2019,Cordeiro2018}, is a bounded model checker for
Java built on the same basis as CBMC.
It uses combination of SAT and SMT solving with a dedicated solver for string
operations.
JBMC has support for exceptions (by lowering them to jumps in its intermediate
representation) and has an exact verification-friendly model of most common
parts of the Java standard libraries.
It can detect assertions, memory errors, integral overflows an type casting
errors.
JBMC has no support for threads currently \TODO{oveřit s SVC 2020}.
It also lacks support for the Java Native Interface (JNI) and reflection.

LLBMC~\cite{Merz2012,Falke2013} is an SMT-based bit-precise BMC for
sequential C and C++ programs which is notable for its used of the LLVM
intermediate representation which allows it to reuse existing C and C++
compilers.
It is also one of the few tools which have support of C++, although with some
limitations, most notably there is not support for exceptions and run-time type
support and there is no support for threads and floating-point arithmetic for
both C and C++.
It can detect assertion violations, integer overflows, invalid shifts, memory
errors and memory leaks.
\TODO{unmaintained}

Another LLVM-base tool is LLVMVF~\cite{Sousa2013} which is a generic verification framework on which a BMC for parallel programs is built.
Concurrency support in LLVMVF is incomplete, for example it lacks support for condition variables.
\TODO{unmaintained}

Yogar-CBMC~\cite{Yin2018,Yin2019} is a derivative of CBMC which uses
abstraction and refinement for the encoding of scheduling constraints in
parallel programs in order to make the formulas smaller.
Unlike CBMC, it has no support for relaxed memory.
It can run multiple counterexample-guided refinement loops in parallel and they
share the learned scheduling constraints in order to analyze the program
faster.
Yogar-CBMC was able to solve all concurrency benchmarks in SV-COMP 2019 and significantly outperformed CBMC.

CBMC-Path~\cite{Khazem2019} is another derivative of CBMC, it encodes paths in
the state space one by one instead of building a formula for the whole
(bounded) state space of a parallel program.
While it was designed to facilitate faster bug discovery for SV-COMP it performed significantly worse than CBMC.

DepthK~\cite{Rocha2017,Rocha2017svc}, is a tool based on ESBMC with
addition of polyhedral invariants which aim to strengthen inductive step in the
$k$-induction.
It was presented before ESBMC gained ability to compute invariants itself and it uses an external tool for invariant generation.
DepthK can analyze concurrent C programs.

\TODO{\textsc{Dartagnan}~\cite{PonceDeLeon2020,Gavrilenko2019}}
- BMC for relaxed memory models, relaxed memory model can be specified on input, not encoded in the verifier
- for C, internally uses \textsc{Boogie} intermediate language (translates using SMACK)
- uses symbolic encoding which encodes relations such as program order, data dependencies, read-from -- memory model specification constraints them
- safety properties
- does not support pointer arithmetic
- should support wide range of memory models including \xtso, ARMv8, POWER, C/C++11 + Linux kernel memory model including primitives such as RCU\mnote{Read-copy-update \TODO{…}}.
- relation analysis to reduce size of the encoding -- determines which pairs of events may influence constraints specified by the memory model

Lazy-CSeq~\cite{Inverso2015,Nguyen2017} is a sequentialization-based
tool for analysis of concurrent C programs which uses bounded model checker as
a backend (CBMC by default).
It performs source-to-source transformation from a concurrent C program to a
sequential C program which simulates a bounded number of round-robin scheduling
rounds (i.e., the number of context switches is limited and the threads are
required to execute in a fixed order, with possibility to perform no steps in a
given round).
This way Lazy-CSeq can simulate a bounded number of interleavings with small
memory overhead and limiting additional nondeterminism compared to the
additional program.
It can detect errors detectable by the used backend, plus POSIX mutex
deadlocks.
In order to speed verification, Lazy-CSeq uses Frama-C~\cite{Canet2009} to
infer  bounds of integral variables and shrink the corresponding bitvector
formulas.
\TODO{\cite{Inverso2020}
- parallelization by partitioning the set of execution traces into independent instances
-
}

\TODO{- the formula size if O(|orig prog.| * |n threads| * |n rounds|)
- Lazy = explores only reachable state space (compared to Akash Lal \& Thomas Reps: Reducing concurrent analysis under a context bound to sequential analysis), does not start after each context switch from nondeterministic values}

MU-CSeq~\cite{Tomasco2015,Tomasco2016} and IMU-CSeq~\cite{Tomasco2017}
are sequentialization-based tools for analysis of concurrent C programs which
uses CBMC as a backend.
They work by nondeterministically guessing a bounded sequence of shared memory
writes and then simulating the program so that its runs match this sequence.
Optionally it can allow also unobserved memory writes which are not part of the
sequence to execute.
The difference between the tools is that IMU-CSeq uses a separate sequence for
each memory location, while MU-CSeq has a single sequence of visible memory
operations.
IMU-CSeq has also support for relaxed memory (TSO, PSO) by the means of
\emph{Shared Memory Abstraction} which defines behaviour of memory operations
and synchronization primitives of the given memory model.

\TODO{- eager = threads are executed separately, with nondeterministic values for shared memory reads, runs are pruned}


---

BLITZ~\cite{Cho2013}
- decomposes the verification instance using approximations of preconditions of property violation which are gradually refined
- the proofs of unsatisfiability (for the under-approximated instance) provide information used for the refinement
- aimed to larger programs (100kloc)
- C programs, including assertions and memory safety
- no mention of paralelism

TCBMC~\cite{Rabinovitz2005}
- context-switch bounded
- extension of CBMC to concurrent programs
- adds support for race and deadlock detection
- only two threads and no deadlocks detection in the implementation

CheckFence~\cite{Burckhardt2007}
- a tool for checking implementations of concurrent data structures in C against a memory model
- Uses a test program as a specification -- it checks if the set of all executions under the given memory model is a subset of a set of \emph{serial executions} which are sequentially consistent executions in which each operation with the data structure is atomic.
- encodes threads and scheduling separately


NBIS~\cite{Gunther2016}
- incremental BMC - can change bounds without throwing away the formula
- uses incremental solvers
- LLVM IR based, for C sequential programs
- not maintained

F-Soft~\cite{Ivancic2005}
- for sequential C programs, safety
- uses BMC (and BDD-based model checking)
- program slicing, predicate abstraction
- generates executable counterexamles

power2sc \mcite{Abdulla2017}

Corral

\paragraph{Limitations of BMC}

- bounded depth
- functions inlined (… function pointers)/recursion bound

\section{K-Induction, IC3, …}

\paragraph{$k$-Induction}


\cite{Donaldson2011}: \textsc{K-Inductor}, \textsc{K-Boogie}
<- CBMC based
-> extension of Boogie
- \TODO{...}

\section{TODO: Misc}

VVT~\cite{Gunther2016}
- CTIGAR = SMT-based IC3 with CEGAR (Counterexample-Guided Abstraction Refinement \TODO{\cite{Birgmeier2014,Bradley2011}}
- parallel C programs
- can analyze infinite-state systems (with finite number of threads, arrays with statically known bounds)
- no unwinding of transition relation
- uses LLVM IR, clang for translation on C
- blocks of instructions which can be executed atomically are identified, context-switch points are instrumented into code
- uses linear arithmetic (to allow interpolation)
- uses a BMC for fast counterexample detection
- not maintained

VIAP~\cite{Rajkhowa2019,Rajkhowa2017}
- aims at programs with loops, does not need invariants
- C programs without dynamic memory, floats, concurrency
- uses integral arithmetic
- translates to quantified first-order formulas over integers
- non-bounded loops
- can use preconditions and postconditions, or assertions

\textsc{Ultimate Automizer}~\cite{Heizmann2017,Heizmann2013}
- C programs, including concurrency
- CEGAR
- automata-theoretic verification approach
- assertion reachability, memory safety, absence of integral overflows, termination
- converts programs to automata (starting with automaton derived from control-flow graph), checks reachability of error states by checking feasibility of error traces
  - the abstraction is refined by counterexample to error trace feasibility
  - refinement by construction of automaton of spurious traces -- Floyd-Hoare automaton (constructed on-demand)
  - uses SMT solver in the refinement
- uses nested words automata for interprocedural analysis~\cite{TODO}
- (non)termination checking~\cite{TODO: Buchy automizer} uses ranking functions and nontermination arguments

\textsc{Ultimate Taipan}~\cite{Dietsch2020,Greitschus2017}
- combines the approach of UA with analysis of \emph{path programs} (projects the original program into an error trace to obtain a corresponding path program which can contain loops (and only contains statements found on the trace)
- attempts to show trace infeasibility by proving unreachability of the error location in the path program using invariants
- newer version uses SMT formulas to represent program states

\textsc{Ultimate Kojak}~\cite{Nutz2015} is another related tool which uses a different algorithm for the refinement step.

Skink~\cite{Cassez2017}
- C programs, supports concurrency
- uses LLVM IR
- uses refinement of trace abstraction algotithm \TODO{(like UAutomizer), cite}
  - uses automata refinement, starting from control-flow automata
  - SMT used to check feasibility of traces
  - for concurrency uses product of thread automata
    - uses POR (based on source-DPOR by \cite{Abdulla2014})
- requires full inlining (no function calls)
- uses integer arithmetic, not bit-precise
- assertion reachability

JayHorn~\cite{Kahsai2019}
-- encoding to horn-clauses, not conucerrency, not bitprecise, basic library (mostly assumes library calls return arbitrary values- can handle certain cases of unbounded heap data structures by deriving invariants, nonterminating programs

CPAchecker~\cite{Dangl2015,Beyer2011}
- C
- a tool and a modular framework which aims at easy integration of new components
- multiple abstract domains can be combined together
- intended as a platform for research of new verification ideas
- k-induction, predicate analysis, …
- bit-precise validation of counterexamples
- memory graphs for memory safety as of~\cite{Dangl2015} (but later in SV-COMP yes)
- reachability, memory safety
- multiple derived tools in SV-COMP
  - CPA-BAM-BnB~\cite{Andrianov2017}
    - BAM = Block Abstraction Memoization: divides program into blocks and analyzes them separately (block = function), cache to reuse block abstractions, uses value analysis and predicate analysis + refinement on spuroious conterexamples
    - BnB -- modelling of memory using predicate analysis, uses uninterpreted functions to map memory locations to memory values, memory is split into regions, each region has its own mapping function.
  - CPALockator~\cite{Andrianov2018}
    - for concurrency, detects race conditions
    - aims to be lightweight at the cost of missed errors
    - tracks locks, which thread are active at given time
    - predicate analysis, CEGAR to exclude spurious race conditions
  - CPA-Seq

SMACK~\cite{Rakamaric2014,Carter2016,Garzella2020}
- translates LLVM IR into Boogie intermediate verification language
- uses Boogie and Corral (default) as backends, intended to allow easy prototyping of backend verifiers
- can use bitvectors or arbitrary-precision ingegers
- boogie does not have dynamic memory -> memory is partitioned into disjoint regions which are represented by maps in boogie
- bug-finder for C and Rust
  - only basic library support (allocation, C string and math operations, pthreads, models of most common Rust libraries)
- \cite{Garzella2020} provides a large study of adding support for C++, Objective-C, D, Fortran, Swift, and Kotlin to SMACK
  - they state models of standard libraries need to be written manually (i.e. reusal not considered)
  - heavy reliance on LLVM for basic support
  - shows limits of SMACK's handling of LLVM
  - only limited support for runtime and libraries (especially in runtime-heavy languages like Swift, Objective-C and Kotlin)
    - pratialy reuse of existing library (Kotlin arithmetics)
    - partly rudimentary models
  - cross-language verification (mostly for free due to LLVM)
- with concurrency-enabled backend (e.g. Corral) supports concurrency

GACAL
- generates potential invariants from traces and verifies them using the ACL2 theorem prover
- only a subset of C (no arrays, only 32 bit integers, …)

Predator/PredatorHP~\cite{Peringer2020,Dudka2013}
- shape analysis of sequential C -- targets memory errors, assertions -> can handle unbounded lists
  - targets programs which use lists (singly/doubly-linked, circular, nested)
  - uses symbolic representation of the memory (symbolic memory graphs)
- only limited handling of non-list types
- uses function summaries, recursion depth bound
- uses GCC compiler
- PredatorHP is an extension which runs several configurations of Predator in parallel (a verifier which can prove correctness but overapproximates and several bug hunters which can show incorrectness)

VeriAbs~\cite{Afzal2019}
- portfolio verifier -- uses different independent techniques for program analysis
- targets sequential C programs with loops
- lightweight analysis to infer which technique should be used, based on the type of loops and data used in them
- techniques include: random fuzz testing, array abstractions, explicit-state model checking, loop invariant generation, CEGAR, loop abstraction, loop summarization, BMC, k-induction

\textsc{PeSCo}~\cite{Richter2019,Czech2017}
- tries to predict order of configurations of a verifier to run on a given task using machine learning
- uses 6 configurations of CPAchecker as a basis
- learning uses graph encoding of programs

VeriFuzz~\cite{Basak2019}
- fuzz testing with lightweight analaysis and instrumentation to extract useful infromation about the program
- coverage driven
- uses evolutionary algorithm to generate test inputs and learning algorithm based on decision trees to decide which techniques to use for fuzzing
- uses loop unrolling (with increasing bounds)

\section{Symbolic Execution}

Introduced in~\cite{King1976}.

Concolic execution = dynamic symbolic execution: programs runs with concrete values but tracks symbolic constraints on branches which are used to generate new concrete values to explore different paths. Also known as Directed Automated Random Testing \cite{Godefroid2005}, 


Symbiotic~\cite{Chalupa2018,Chalupa2020}
- for sequential C programs
- assertions, memory safety, memory leaks, integral overflows
- uses instrumentation to add checks where needed (pointer analysis to limit number of inserted checks)
  - pointer analysis has to account for deallocation
- slicing to remove code irrelevant for the property 
- uses Klee symbolic executor as a backend
- integrates shape analysis based on Predator\cite{TODO} for memory safety checking
- basic non/termination
    - can detect simple cycles in the program state space and therefore in some cases decide the program does not terminate (non-nested loops which preserve values of all variables)
    - can conclude the program is termingating if all paths were explored
- sequential programs

Pinaka~\cite{Chaudhary2019}
- C
- uses incremental solver to check path feasibility (either fully incremental -- reuses one solver instance for the whole program, which can cause big formulas, or partially incremental -- creates new instance on backtracking)
- may not terminate on nonterminating programs, option for unwinding limit
- can be used to show termination -- if program is found to be safe without any unwinding limit, then all its paths terminate

\textsc{JDart}~\cite{Mues2020,Luckow2016}
- java, assertion checking, uncaught exceptions
- concolic execution, test generation
- attempts to find small values for symbolic variables (can make loops depending on symbolic values shorter)
- built on JPF
- no concurrency

Java Ranger~\cite{Sharma2020}
- symbolic execution with path merging by summarization of regions with multiple paths (e.g., branches of an \texttt{if} statement) (\TODO{veritesting})
- extension of SPF

COASTAL~\cite{Visser2020}
- concolic execution + fuzz testing for Java
- uses instrumentation
- can explore different parts of the symbolic execution tree in parallel (with different fuzzer or concolic executor instances)
- fuzz testing can be used for fast exploration, it tracks only direction of branches
- in combilation uses fuzz testing to explore easily-accessible parts of state space and concolic execution to get to the harder
- uses models for some Java classses, but seems to be able to handle original java bitecode libraries (?)
- no symbolic arrays

Map2Check~\cite{Rocha2020}
- fuzzing, symbolic execution, inductive invariants for safety checking C programs
- uses LLVM, Klee
- no concurrency
- fuzzing used to find shallow bugs, symbolic execution for deep
- can use multiple fuzzers in parallel

Map2Check~\cite{Rocha2015} (previous version)
- memory safety + memory safety unit test generation for C using ESBMC
  - including memory leaks, invalid free
- ESBMC used to extract verification conditions (e.g., conditions of memory safety violation)
- program is then instrumented convert memory safety to assertions about pointers
- tests are executed (with concrete data)

Threader~\cite{Gupta2011}
- compositional verification of parallel programs, thread-modular proofs for C programs
- Horn clause encoding
- uses compositional proof rules for concurrent programs~\cite{Jones1983,Owicki1976}
- abstract reachability + refinement
- not limited to specific synchronization primitives
- safety (assertions), can also prove termination properties

\section{Abstraction-Based Techniques}

\section{Systematic Testing}

\section{Control-Flow Analysis Techniques}

\section{??? Termination and Temporal Logics}

- sequential LTL (inf systems, inc. termination analysis): \cite{Dietsch2015}
- other liveness in sequential C (inf sys, Terminator): \cite{Cook2007} (drivers)
- termination (seq, ptr, inf, \textsc{Terminator}): \cite{Cook2006}
- termination (inc. heap): \cite{Berdine2006}
- termination+nontermination (C, Java, Haskell, Prolog, recurstion, ptr, bitvectors (bit-precise); seq no structs): AProVe \cite{Hensel2017, Giesl2017}

T2~\cite{Brockschmidt2016}
- open source release of the Terminator
- liveness + safety
- no concurrency, heap, recursion

\section{XXX}

\section{Real-World Parallel Programs}


\section{Relaxed Memory Models}

There are numerous techniques for analysis of programs with respect to relaxed memory.

\paragraph{Verification of Absence of SC Violations}

For these methods, the question is whether a program, when running under a relaxed memory model, exhibits any runs not possible under sequential consistency.
This problem is explored under many names, e.g. (TSO-)safety~\cite{Burckhardt2008}, robustness~\cite{Bouajjani2013,Derevenetc2014}, stability~\cite{Alglave2011}, and monitoring of sequential consistency~\cite{Burnim2011}.
A similar techniques are used in \cite{Yang2004} to detect data races in Java programs.
A related problem of correspondence between a parallel and sequential implementation of a data structure is explored in~\cite{Ou2017}.
Some of these techniques can also be used to insert memory fences into the programs to recover sequential consistency.

Neither of these techniques is directly comparable to our method.
For these techniques, a program is incorrect if it exhibits relaxed behavior, while for us, it is incorrect if it violates specification (e.g., assertion safety and memory safety).
In practice, the appearance of relaxed behavior is often not a problem, provided the overall behavior of the data structure or algorithm matches desired specification.
In many lock-free data structures, a relaxed behavior is essential to achieving high performance.

\paragraph{Direct Analysis Techniques}

There are multiple methods for analysis of relaxed memory models based on program transformation.
In~\cite{Alglave2013} a transformation-based technique for the x86, POWER, and ARM memory models is presented.
Another approach to program transformation is taken in~\cite{Atig2011}, in this case, the transformation uses context switch bounding but not buffer bounding, and it uses additional copies for shared variables for TSO simulation.
In~\cite{Abdulla2017} the context-bounded analysis using transformation is applied to the POWER memory model.
Our work in~\cite{SRB15weakmem} presents a transformation of LLVM bitcode to simulate buffer-bounded \xtso runs; compared to this work it has significantly less efficient implementation of the \xtso simulation.


So far, all of the described techniques used some kind of bounding to achieve efficiency -- either bounding number of reordered operations, number of context switches, or number of iterations of loops.
An unbounded approach to verification of programs under TSO is presented in~\cite{Linden2010}.
It uses store buffers represented by automata and leverages cycle iteration acceleration to get a representation of store buffers on paths which would form cycles if values in store buffers were disregarded.
It does not, however, target any real-world programming language.
Instead, it targets a modified Promela language~\cite{Holzmann1997}.
Another unbounded approach is presented in~\cite{Bouajjani2015} -- it introduces TSO behaviors lazily by iterative refinement, and while it is not complete, it should eventually find all errors.

\paragraph{Other Methods}\label{other-methods}

In~\cite{Park1995}, the SPARC hierarchy of memory models (TSO, PSO, RMO) is modeled using encoding from assembly to Mur\(\varphi\)~\cite{Murphi}.
In~\cite{Huynh2006} an explicit state model checker for C\# programs (supporting subset of C\#/.NET bytecode) which uses the .NET memory model is presented.
The verifier first verifies program under SC and then it explores additional runs allowed under the .NET memory model.
The implementation of the exploration algorithm uses a list of delayed instructions to implement instruction reordering.
The work~\cite{Dan2013} presents verification of (potentially infinite state space) programs under TSO and PSO (with bounded store buffers) using predicate abstraction.

A completely different approach is taken in~\cite{Turon2014}.
This work introduces a separation logic GPS, which allows proving properties about programs using (a fragment of) the C11 memory model.
That is, this work is intended for manual proving of properties of parallel programs, not for automatic verification.
The memory model is not complete; it lacks relaxed and consume-release accesses.
Another fragment of the C11 memory model is targeted by the RSL separation logic introduced in~\cite{Vafeiadis2013}.

\section{Termination of Parallel Programs}

For the related work, we consider only results which go beyond safety checking.
There are many approaches to find problems such as assertion violations or memory safety violations, but they are fundamentally limited to properties concerning finite runs of the program, and we are focusing here on an infinite behaviour, namely on the absence of termination.
Similarly, we do not mention techniques which specialise on checking sequential programs and have no support for parallelism, as well as techniques which are tailored to a specific modelling language and cannot be applied in general.

Several techniques for checking properties other than safety exist -- indeed
usage of various temporal logics, such as Linear Temporal Logic (LTL)
\cite[Chapter 5]{PoMC} and Computation Tree Logic (CTL) \cite[Chapter 6]{PoMC} in the context of model checking dates way back to the beginning of research in formal methods.
Unfortunately, these techniques are not often applied to programs written in real-world programming languages such as C and C++.

As for techniques which detect nontermination, both static and dynamic
techniques exist for the detection of deadlocks caused by circular waiting for
mutexes~\cite{CC14,agarwal2010detection,bensalem2005scalable}.
However, these techniques specialise on mutexes and do not allow general nontermination detection, and it is unlikely that they could be naturally extended to cover it.
There are also techniques that detect deadlocks of the whole program (i.e., a program state from which the program cannot move) \cite{Chaki2005,Demartini99}, but these techniques cannot find cases in which only some threads of the program are making progress, while other threads are blocked forever.
Also, these global deadlock detection techniques are inadequate in the presence of synchronisation mechanisms which causes busy waiting instead of blocking (for example spin locks) or in the cases when normally blocking operations are implemented using busy waiting (which can be easier to handle for the verifier in some cases).
A somewhat different approach based on communicating channels is proposed in \cite{Ng2016}, but this approach is aiming at the Go programming language which primarily uses shared channels for communication between threads.
Overall, neither of these techniques is applicable in general for the detection of nontermination in programs which use a combination of synchronisation primitives in shared memory.
Finally, there are also techniques for checking termination of sequential programs, to name a few \cite{Giesl2017,Chen2018}.

\section{Termination Checking}

SACO~\cite{Albert2017}
- for analysis of concurrent programs with loops
- uses may-happen-in-parallel analysis to infer which part of the program can interfere
- also infer upper bounds on iteration numbers
- for modelling language (with shared memory)
- generates constraints on how the shared state can be modified in order for the loop to terminate and than checks that this will eventually hold

2LS~\cite{Malik2020,Malik2018,Chen2017}
- built on CPROVER (the backend of CBMC)
- interprocedural termination analysis for sequential programs
- bounded model checking with k-induction and abstract interpretation
- sequential C programs
- bit-precise
- assertions, (non-)termination
- template-based synthesis for invariants and ranking functions
- shape domain for heap analysis
  - shape and content of the dynamic memory
  - takes address reuse into account
  - combination of abstract domains
- termination analysis based on lexicographical linear orders
- simple nontermination proofs for loops (repeated loop state; loops which iterate over numerical variables with constant increments in a way they cannot end)
- no recursion, arrays, concurrency

Arctor~\cite{Kupriyanov2014}
- for concurrency
- based on abstraction and refinement
- based on well-founded relations
- can show termination, or possibly non-terminating execution


~\cite{Cook2007thr}
- Other threads are abstracted into a model of environment which is incrementally refined
- termination proving for threads (thread termination proving)


\section{Benchmark Suites}

- \cite{Sarkar2011,MadorHaim2012} POWER tests
- http://www.cprover.org/wmm/
- ESBMC (\cite{Cordeiro2011}): http://users.ecs.soton.ac.uk/lcc08r/esbmc/
- ESBMC++ \cite{Ramalho2016:19,6,27,.} (sec. IV.A. Experimental Setup)
- BLITZ:
  - Bugbench: % https://scholar.google.com/scholar?as_q=Bugbench%3A+Benchmarks+for+evaluating+bug+detection+tools&as_occt=title&hl=en&as_sdt=0%2C31
  - tools from http://www.isc.org/

\section{MISC}

- need for environemnt and application intefrace modelling: \cite{Cordeiro2016}

% vim: colorcolumn=80 expandtab sw=4 ts=4 spell spelllang=en
